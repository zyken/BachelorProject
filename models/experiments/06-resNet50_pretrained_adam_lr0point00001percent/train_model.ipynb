{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_plot_name = \"trainplot.png\"\n",
    "model_name = 'highest_val_acc.h5'\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.0000001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/herri/.local/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/herri/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=10)\n",
    "\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4088/4088 [==============================] - 490s 120ms/step - loss: 5.4834 - acc: 0.0060 - val_loss: 5.5953 - val_acc: 0.0056\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00561, saving model to highest_val_acc.h5\n",
      "Epoch 2/5000\n",
      "4088/4088 [==============================] - 478s 117ms/step - loss: 5.4164 - acc: 0.0078 - val_loss: 5.5125 - val_acc: 0.0071\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.00561 to 0.00709, saving model to highest_val_acc.h5\n",
      "Epoch 3/5000\n",
      "4088/4088 [==============================] - 480s 117ms/step - loss: 5.3573 - acc: 0.0116 - val_loss: 5.4453 - val_acc: 0.0083\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.00709 to 0.00827, saving model to highest_val_acc.h5\n",
      "Epoch 4/5000\n",
      "4088/4088 [==============================] - 480s 117ms/step - loss: 5.2940 - acc: 0.0133 - val_loss: 5.3753 - val_acc: 0.0100\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.00827 to 0.01005, saving model to highest_val_acc.h5\n",
      "Epoch 5/5000\n",
      "4088/4088 [==============================] - 480s 117ms/step - loss: 5.2431 - acc: 0.0170 - val_loss: 5.3176 - val_acc: 0.0145\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.01005 to 0.01448, saving model to highest_val_acc.h5\n",
      "Epoch 6/5000\n",
      "4088/4088 [==============================] - 480s 117ms/step - loss: 5.1874 - acc: 0.0236 - val_loss: 5.2648 - val_acc: 0.0165\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.01448 to 0.01655, saving model to highest_val_acc.h5\n",
      "Epoch 7/5000\n",
      "4088/4088 [==============================] - 485s 119ms/step - loss: 5.1382 - acc: 0.0303 - val_loss: 5.1900 - val_acc: 0.0198\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.01655 to 0.01980, saving model to highest_val_acc.h5\n",
      "Epoch 8/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 5.0823 - acc: 0.0355 - val_loss: 5.1324 - val_acc: 0.0263\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.01980 to 0.02630, saving model to highest_val_acc.h5\n",
      "Epoch 9/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 5.0368 - acc: 0.0421 - val_loss: 5.0669 - val_acc: 0.0337\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.02630 to 0.03369, saving model to highest_val_acc.h5\n",
      "Epoch 10/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.9892 - acc: 0.0491 - val_loss: 5.0084 - val_acc: 0.0390\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.03369 to 0.03901, saving model to highest_val_acc.h5\n",
      "Epoch 11/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.9425 - acc: 0.0540 - val_loss: 4.9425 - val_acc: 0.0499\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.03901 to 0.04994, saving model to highest_val_acc.h5\n",
      "Epoch 12/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.8938 - acc: 0.0643 - val_loss: 4.8818 - val_acc: 0.0556\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.04994 to 0.05556, saving model to highest_val_acc.h5\n",
      "Epoch 13/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.8426 - acc: 0.0740 - val_loss: 4.8065 - val_acc: 0.0671\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.05556 to 0.06708, saving model to highest_val_acc.h5\n",
      "Epoch 14/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.7941 - acc: 0.0788 - val_loss: 4.7617 - val_acc: 0.0721\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.06708 to 0.07210, saving model to highest_val_acc.h5\n",
      "Epoch 15/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.7518 - acc: 0.0832 - val_loss: 4.6874 - val_acc: 0.0774\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.07210 to 0.07742, saving model to highest_val_acc.h5\n",
      "Epoch 16/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.6999 - acc: 0.0904 - val_loss: 4.6199 - val_acc: 0.0866\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.07742 to 0.08658, saving model to highest_val_acc.h5\n",
      "Epoch 17/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.6538 - acc: 0.0952 - val_loss: 4.5585 - val_acc: 0.0872\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.08658 to 0.08717, saving model to highest_val_acc.h5\n",
      "Epoch 18/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.6097 - acc: 0.1005 - val_loss: 4.5131 - val_acc: 0.0937\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.08717 to 0.09368, saving model to highest_val_acc.h5\n",
      "Epoch 19/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.5673 - acc: 0.1078 - val_loss: 4.4451 - val_acc: 0.1025\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.09368 to 0.10254, saving model to highest_val_acc.h5\n",
      "Epoch 20/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.5167 - acc: 0.1156 - val_loss: 4.4002 - val_acc: 0.1082\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.10254 to 0.10816, saving model to highest_val_acc.h5\n",
      "Epoch 21/5000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 4.4733 - acc: 0.1173 - val_loss: 4.3298 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.10816 to 0.11348, saving model to highest_val_acc.h5\n",
      "Epoch 22/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.4305 - acc: 0.1279 - val_loss: 4.2806 - val_acc: 0.1244\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.11348 to 0.12441, saving model to highest_val_acc.h5\n",
      "Epoch 23/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.3929 - acc: 0.1316 - val_loss: 4.2373 - val_acc: 0.1300\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.12441 to 0.13002, saving model to highest_val_acc.h5\n",
      "Epoch 24/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.3560 - acc: 0.1406 - val_loss: 4.1737 - val_acc: 0.1389\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.13002 to 0.13889, saving model to highest_val_acc.h5\n",
      "Epoch 25/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.3060 - acc: 0.1456 - val_loss: 4.1361 - val_acc: 0.1448\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.13889 to 0.14480, saving model to highest_val_acc.h5\n",
      "Epoch 26/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.2773 - acc: 0.1551 - val_loss: 4.0816 - val_acc: 0.1554\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.14480 to 0.15544, saving model to highest_val_acc.h5\n",
      "Epoch 27/5000\n",
      "4088/4088 [==============================] - 490s 120ms/step - loss: 4.2308 - acc: 0.1627 - val_loss: 4.0312 - val_acc: 0.1622\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.15544 to 0.16223, saving model to highest_val_acc.h5\n",
      "Epoch 28/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.1905 - acc: 0.1694 - val_loss: 3.9686 - val_acc: 0.1720\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.16223 to 0.17199, saving model to highest_val_acc.h5\n",
      "Epoch 29/5000\n",
      "4088/4088 [==============================] - 490s 120ms/step - loss: 4.1551 - acc: 0.1748 - val_loss: 3.9363 - val_acc: 0.1746\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.17199 to 0.17465, saving model to highest_val_acc.h5\n",
      "Epoch 30/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.1155 - acc: 0.1800 - val_loss: 3.8809 - val_acc: 0.1835\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.17465 to 0.18351, saving model to highest_val_acc.h5\n",
      "Epoch 31/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.0840 - acc: 0.1856 - val_loss: 3.8369 - val_acc: 0.1894\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.18351 to 0.18942, saving model to highest_val_acc.h5\n",
      "Epoch 32/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.0516 - acc: 0.1893 - val_loss: 3.7997 - val_acc: 0.1968\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.18942 to 0.19681, saving model to highest_val_acc.h5\n",
      "Epoch 33/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 4.0075 - acc: 0.2001 - val_loss: 3.7598 - val_acc: 0.2054\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.19681 to 0.20538, saving model to highest_val_acc.h5\n",
      "Epoch 34/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 3.9702 - acc: 0.2028 - val_loss: 3.7013 - val_acc: 0.2086\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.20538 to 0.20863, saving model to highest_val_acc.h5\n",
      "Epoch 35/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 3.9414 - acc: 0.2037 - val_loss: 3.6487 - val_acc: 0.2160\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.20863 to 0.21602, saving model to highest_val_acc.h5\n",
      "Epoch 36/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.9070 - acc: 0.2094 - val_loss: 3.6208 - val_acc: 0.2202\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.21602 to 0.22015, saving model to highest_val_acc.h5\n",
      "Epoch 37/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.8804 - acc: 0.2155 - val_loss: 3.5607 - val_acc: 0.2264\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.22015 to 0.22636, saving model to highest_val_acc.h5\n",
      "Epoch 38/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.8459 - acc: 0.2215 - val_loss: 3.5295 - val_acc: 0.2358\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.22636 to 0.23582, saving model to highest_val_acc.h5\n",
      "Epoch 39/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.8040 - acc: 0.2261 - val_loss: 3.4897 - val_acc: 0.2414\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.23582 to 0.24143, saving model to highest_val_acc.h5\n",
      "Epoch 40/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.7794 - acc: 0.2332 - val_loss: 3.4861 - val_acc: 0.2402\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.24143\n",
      "Epoch 41/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.7498 - acc: 0.2355 - val_loss: 3.4216 - val_acc: 0.2479\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.24143 to 0.24793, saving model to highest_val_acc.h5\n",
      "Epoch 42/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.7096 - acc: 0.2461 - val_loss: 3.3875 - val_acc: 0.2586\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.24793 to 0.25857, saving model to highest_val_acc.h5\n",
      "Epoch 43/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.6822 - acc: 0.2484 - val_loss: 3.3554 - val_acc: 0.2603\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.25857 to 0.26034, saving model to highest_val_acc.h5\n",
      "Epoch 44/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.6579 - acc: 0.2491 - val_loss: 3.3238 - val_acc: 0.2639\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.26034 to 0.26389, saving model to highest_val_acc.h5\n",
      "Epoch 45/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.6211 - acc: 0.2570 - val_loss: 3.2943 - val_acc: 0.2680\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.26389 to 0.26803, saving model to highest_val_acc.h5\n",
      "Epoch 46/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.5932 - acc: 0.2587 - val_loss: 3.2623 - val_acc: 0.2707\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.26803 to 0.27069, saving model to highest_val_acc.h5\n",
      "Epoch 47/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.5716 - acc: 0.2684 - val_loss: 3.2167 - val_acc: 0.2781\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.27069 to 0.27807, saving model to highest_val_acc.h5\n",
      "Epoch 48/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.5372 - acc: 0.2697 - val_loss: 3.1794 - val_acc: 0.2798\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.27807 to 0.27985, saving model to highest_val_acc.h5\n",
      "Epoch 49/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.5127 - acc: 0.2756 - val_loss: 3.1611 - val_acc: 0.2881\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.27985 to 0.28812, saving model to highest_val_acc.h5\n",
      "Epoch 50/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.4804 - acc: 0.2801 - val_loss: 3.1250 - val_acc: 0.2976\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.28812 to 0.29758, saving model to highest_val_acc.h5\n",
      "Epoch 51/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.4540 - acc: 0.2916 - val_loss: 3.0846 - val_acc: 0.2955\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.29758\n",
      "Epoch 52/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.4215 - acc: 0.2972 - val_loss: 3.0650 - val_acc: 0.2999\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.29758 to 0.29994, saving model to highest_val_acc.h5\n",
      "Epoch 53/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.3998 - acc: 0.2977 - val_loss: 3.0332 - val_acc: 0.3100\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.29994 to 0.30999, saving model to highest_val_acc.h5\n",
      "Epoch 54/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.3730 - acc: 0.2988 - val_loss: 3.0073 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.30999 to 0.31472, saving model to highest_val_acc.h5\n",
      "Epoch 55/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.3361 - acc: 0.3094 - val_loss: 2.9825 - val_acc: 0.3168\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.31472 to 0.31678, saving model to highest_val_acc.h5\n",
      "Epoch 56/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.3150 - acc: 0.3114 - val_loss: 2.9459 - val_acc: 0.3242\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.31678 to 0.32417, saving model to highest_val_acc.h5\n",
      "Epoch 57/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.2969 - acc: 0.3136 - val_loss: 2.9212 - val_acc: 0.3257\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.32417 to 0.32565, saving model to highest_val_acc.h5\n",
      "Epoch 58/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.2639 - acc: 0.3187 - val_loss: 2.8887 - val_acc: 0.3277\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.32565 to 0.32772, saving model to highest_val_acc.h5\n",
      "Epoch 59/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.2428 - acc: 0.3205 - val_loss: 2.8596 - val_acc: 0.3351\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.32772 to 0.33511, saving model to highest_val_acc.h5\n",
      "Epoch 60/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.2127 - acc: 0.3310 - val_loss: 2.8399 - val_acc: 0.3348\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.33511\n",
      "Epoch 61/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.1928 - acc: 0.3362 - val_loss: 2.8108 - val_acc: 0.3457\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.33511 to 0.34574, saving model to highest_val_acc.h5\n",
      "Epoch 62/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.1595 - acc: 0.3385 - val_loss: 2.7876 - val_acc: 0.3454\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.34574\n",
      "Epoch 63/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.1398 - acc: 0.3444 - val_loss: 2.7523 - val_acc: 0.3558\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.34574 to 0.35579, saving model to highest_val_acc.h5\n",
      "Epoch 64/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.1197 - acc: 0.3470 - val_loss: 2.7338 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.35579\n",
      "Epoch 65/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.0790 - acc: 0.3569 - val_loss: 2.7112 - val_acc: 0.3629\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.35579 to 0.36288, saving model to highest_val_acc.h5\n",
      "Epoch 66/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.0656 - acc: 0.3580 - val_loss: 2.6803 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.36288 to 0.37559, saving model to highest_val_acc.h5\n",
      "Epoch 67/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.0366 - acc: 0.3628 - val_loss: 2.6719 - val_acc: 0.3670\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.37559\n",
      "Epoch 68/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 3.0095 - acc: 0.3685 - val_loss: 2.6454 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.37559 to 0.37796, saving model to highest_val_acc.h5\n",
      "Epoch 69/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.9822 - acc: 0.3740 - val_loss: 2.6002 - val_acc: 0.3815\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.37796 to 0.38150, saving model to highest_val_acc.h5\n",
      "Epoch 70/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.9716 - acc: 0.3764 - val_loss: 2.6013 - val_acc: 0.3788\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.38150\n",
      "Epoch 71/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.9468 - acc: 0.3820 - val_loss: 2.5644 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.38150 to 0.39687, saving model to highest_val_acc.h5\n",
      "Epoch 72/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.9259 - acc: 0.3868 - val_loss: 2.5197 - val_acc: 0.3960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_acc did not improve from 0.39687\n",
      "Epoch 73/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.8871 - acc: 0.3886 - val_loss: 2.5246 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.39687 to 0.39775, saving model to highest_val_acc.h5\n",
      "Epoch 74/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.8725 - acc: 0.3960 - val_loss: 2.4753 - val_acc: 0.4122\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.39775 to 0.41223, saving model to highest_val_acc.h5\n",
      "Epoch 75/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.8518 - acc: 0.4035 - val_loss: 2.4888 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.41223\n",
      "Epoch 76/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.8379 - acc: 0.4058 - val_loss: 2.4326 - val_acc: 0.4226\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.41223 to 0.42258, saving model to highest_val_acc.h5\n",
      "Epoch 77/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.8148 - acc: 0.4089 - val_loss: 2.4200 - val_acc: 0.4252\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.42258 to 0.42524, saving model to highest_val_acc.h5\n",
      "Epoch 78/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.7859 - acc: 0.4138 - val_loss: 2.4051 - val_acc: 0.4202\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.42524\n",
      "Epoch 79/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.7675 - acc: 0.4229 - val_loss: 2.3812 - val_acc: 0.4368\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.42524 to 0.43676, saving model to highest_val_acc.h5\n",
      "Epoch 80/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.7425 - acc: 0.4231 - val_loss: 2.3316 - val_acc: 0.4362\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.43676\n",
      "Epoch 81/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.7236 - acc: 0.4258 - val_loss: 2.3451 - val_acc: 0.4459\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.43676 to 0.44592, saving model to highest_val_acc.h5\n",
      "Epoch 82/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 2.6996 - acc: 0.4327 - val_loss: 2.3124 - val_acc: 0.4400\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.44592\n",
      "Epoch 83/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 2.6687 - acc: 0.4401 - val_loss: 2.3005 - val_acc: 0.4524\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.44592 to 0.45242, saving model to highest_val_acc.h5\n",
      "Epoch 84/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 2.6541 - acc: 0.4446 - val_loss: 2.2642 - val_acc: 0.4539\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.45242 to 0.45390, saving model to highest_val_acc.h5\n",
      "Epoch 85/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 2.6237 - acc: 0.4523 - val_loss: 2.2698 - val_acc: 0.4521\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.45390\n",
      "Epoch 86/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 2.6048 - acc: 0.4546 - val_loss: 2.2202 - val_acc: 0.4542\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.45390 to 0.45420, saving model to highest_val_acc.h5\n",
      "Epoch 87/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 2.5932 - acc: 0.4590 - val_loss: 2.2189 - val_acc: 0.4634\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.45420 to 0.46336, saving model to highest_val_acc.h5\n",
      "Epoch 88/5000\n",
      "4088/4088 [==============================] - 473s 116ms/step - loss: 2.5741 - acc: 0.4627 - val_loss: 2.2032 - val_acc: 0.4666\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.46336 to 0.46661, saving model to highest_val_acc.h5\n",
      "Epoch 89/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 2.5445 - acc: 0.4697 - val_loss: 2.1788 - val_acc: 0.4731\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.46661 to 0.47311, saving model to highest_val_acc.h5\n",
      "Epoch 90/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 2.5318 - acc: 0.4694 - val_loss: 2.1472 - val_acc: 0.4790\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.47311 to 0.47902, saving model to highest_val_acc.h5\n",
      "Epoch 91/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.5026 - acc: 0.4756 - val_loss: 2.1354 - val_acc: 0.4775\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.47902\n",
      "Epoch 92/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.4846 - acc: 0.4793 - val_loss: 2.1055 - val_acc: 0.4852\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.47902 to 0.48522, saving model to highest_val_acc.h5\n",
      "Epoch 93/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.4696 - acc: 0.4864 - val_loss: 2.0937 - val_acc: 0.4935\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.48522 to 0.49350, saving model to highest_val_acc.h5\n",
      "Epoch 94/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.4529 - acc: 0.4898 - val_loss: 2.0798 - val_acc: 0.4897\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.49350\n",
      "Epoch 95/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.4237 - acc: 0.4932 - val_loss: 2.0734 - val_acc: 0.4926\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.49350\n",
      "Epoch 96/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.4063 - acc: 0.4974 - val_loss: 2.0576 - val_acc: 0.4905\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.49350\n",
      "Epoch 97/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.3834 - acc: 0.5036 - val_loss: 2.0021 - val_acc: 0.5089\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.49350 to 0.50887, saving model to highest_val_acc.h5\n",
      "Epoch 98/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.3742 - acc: 0.5055 - val_loss: 2.0199 - val_acc: 0.5006\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.50887\n",
      "Epoch 99/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.3462 - acc: 0.5104 - val_loss: 1.9829 - val_acc: 0.5068\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.50887\n",
      "Epoch 100/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.3299 - acc: 0.5176 - val_loss: 1.9678 - val_acc: 0.5089\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.50887\n",
      "Epoch 101/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.3089 - acc: 0.5216 - val_loss: 1.9543 - val_acc: 0.5163\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.50887 to 0.51625, saving model to highest_val_acc.h5\n",
      "Epoch 102/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.2912 - acc: 0.5228 - val_loss: 1.9240 - val_acc: 0.5201\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.51625 to 0.52009, saving model to highest_val_acc.h5\n",
      "Epoch 103/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.2715 - acc: 0.5296 - val_loss: 1.9188 - val_acc: 0.5245\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.52009 to 0.52453, saving model to highest_val_acc.h5\n",
      "Epoch 104/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.2510 - acc: 0.5353 - val_loss: 1.8967 - val_acc: 0.5225\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.52453\n",
      "Epoch 105/5000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 2.2213 - acc: 0.5399 - val_loss: 1.8968 - val_acc: 0.5272\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.52453 to 0.52719, saving model to highest_val_acc.h5\n",
      "Epoch 106/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.2095 - acc: 0.5426 - val_loss: 1.8687 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.52719\n",
      "Epoch 107/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.1905 - acc: 0.5458 - val_loss: 1.8470 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.52719 to 0.53132, saving model to highest_val_acc.h5\n",
      "Epoch 108/5000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.1784 - acc: 0.5505 - val_loss: 1.8466 - val_acc: 0.5384\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.53132 to 0.53842, saving model to highest_val_acc.h5\n",
      "Epoch 109/5000\n",
      "4088/4088 [==============================] - 583s 143ms/step - loss: 2.1552 - acc: 0.5605 - val_loss: 1.8282 - val_acc: 0.5358\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.53842\n",
      "Epoch 110/5000\n",
      "4088/4088 [==============================] - 479s 117ms/step - loss: 2.1361 - acc: 0.5556 - val_loss: 1.7945 - val_acc: 0.5428\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.53842 to 0.54285, saving model to highest_val_acc.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/5000\n",
      "4088/4088 [==============================] - 478s 117ms/step - loss: 2.1244 - acc: 0.5577 - val_loss: 1.8070 - val_acc: 0.5405\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.54285\n",
      "Epoch 112/5000\n",
      "4088/4088 [==============================] - 496s 121ms/step - loss: 2.1154 - acc: 0.5616 - val_loss: 1.7881 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.54285\n",
      "Epoch 113/5000\n",
      "4088/4088 [==============================] - 1001s 245ms/step - loss: 2.0865 - acc: 0.5704 - val_loss: 1.7488 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.54285 to 0.55467, saving model to highest_val_acc.h5\n",
      "Epoch 114/5000\n",
      "4088/4088 [==============================] - 1153s 282ms/step - loss: 2.0674 - acc: 0.5687 - val_loss: 1.7559 - val_acc: 0.5517\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.55467\n",
      "Epoch 115/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 2.0521 - acc: 0.5769 - val_loss: 1.7375 - val_acc: 0.5488\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.55467\n",
      "Epoch 116/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 2.0326 - acc: 0.5771 - val_loss: 1.7408 - val_acc: 0.5582\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.55467 to 0.55822, saving model to highest_val_acc.h5\n",
      "Epoch 117/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 2.0191 - acc: 0.5781 - val_loss: 1.7058 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.55822 to 0.56087, saving model to highest_val_acc.h5\n",
      "Epoch 118/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.9932 - acc: 0.5877 - val_loss: 1.6809 - val_acc: 0.5730\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.56087 to 0.57299, saving model to highest_val_acc.h5\n",
      "Epoch 119/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.9838 - acc: 0.5890 - val_loss: 1.6777 - val_acc: 0.5618\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.57299\n",
      "Epoch 120/5000\n",
      "4088/4088 [==============================] - 1328s 325ms/step - loss: 1.9696 - acc: 0.5921 - val_loss: 1.6694 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.57299\n",
      "Epoch 121/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 1.9495 - acc: 0.5986 - val_loss: 1.6546 - val_acc: 0.5754\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.57299 to 0.57535, saving model to highest_val_acc.h5\n",
      "Epoch 122/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.9357 - acc: 0.6031 - val_loss: 1.6429 - val_acc: 0.5730\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.57535\n",
      "Epoch 123/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 1.9102 - acc: 0.6084 - val_loss: 1.5962 - val_acc: 0.5869\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.57535 to 0.58688, saving model to highest_val_acc.h5\n",
      "Epoch 124/5000\n",
      "4088/4088 [==============================] - 1320s 323ms/step - loss: 1.8929 - acc: 0.6136 - val_loss: 1.6167 - val_acc: 0.5742\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.58688\n",
      "Epoch 125/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 1.8761 - acc: 0.6140 - val_loss: 1.6109 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.58688\n",
      "Epoch 126/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.8670 - acc: 0.6166 - val_loss: 1.5865 - val_acc: 0.5898\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.58688 to 0.58983, saving model to highest_val_acc.h5\n",
      "Epoch 127/5000\n",
      "4088/4088 [==============================] - 1319s 323ms/step - loss: 1.8475 - acc: 0.6212 - val_loss: 1.5774 - val_acc: 0.5845\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.58983\n",
      "Epoch 128/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.8368 - acc: 0.6214 - val_loss: 1.5779 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.58983\n",
      "Epoch 129/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.8180 - acc: 0.6283 - val_loss: 1.5305 - val_acc: 0.5922\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.58983 to 0.59220, saving model to highest_val_acc.h5\n",
      "Epoch 130/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.8005 - acc: 0.6286 - val_loss: 1.5413 - val_acc: 0.5931\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.59220 to 0.59309, saving model to highest_val_acc.h5\n",
      "Epoch 131/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.7867 - acc: 0.6358 - val_loss: 1.5140 - val_acc: 0.6017\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.59309 to 0.60165, saving model to highest_val_acc.h5\n",
      "Epoch 132/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 1.7745 - acc: 0.6388 - val_loss: 1.5382 - val_acc: 0.5984\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.60165\n",
      "Epoch 133/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.7536 - acc: 0.6401 - val_loss: 1.4976 - val_acc: 0.5975\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.60165\n",
      "Epoch 134/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.7404 - acc: 0.6427 - val_loss: 1.5008 - val_acc: 0.6076\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.60165 to 0.60757, saving model to highest_val_acc.h5\n",
      "Epoch 135/5000\n",
      "4088/4088 [==============================] - 1320s 323ms/step - loss: 1.7244 - acc: 0.6497 - val_loss: 1.4620 - val_acc: 0.6120\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.60757 to 0.61200, saving model to highest_val_acc.h5\n",
      "Epoch 136/5000\n",
      "4088/4088 [==============================] - 1319s 323ms/step - loss: 1.7146 - acc: 0.6475 - val_loss: 1.4751 - val_acc: 0.6046\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.61200\n",
      "Epoch 137/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.6991 - acc: 0.6529 - val_loss: 1.4334 - val_acc: 0.6182\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.61200 to 0.61820, saving model to highest_val_acc.h5\n",
      "Epoch 138/5000\n",
      "4088/4088 [==============================] - 1321s 323ms/step - loss: 1.6857 - acc: 0.6586 - val_loss: 1.4755 - val_acc: 0.6011\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.61820\n",
      "Epoch 139/5000\n",
      "4088/4088 [==============================] - 1323s 324ms/step - loss: 1.6773 - acc: 0.6554 - val_loss: 1.4385 - val_acc: 0.6135\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.61820\n",
      "Epoch 140/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.6592 - acc: 0.6621 - val_loss: 1.4327 - val_acc: 0.6194\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.61820 to 0.61939, saving model to highest_val_acc.h5\n",
      "Epoch 141/5000\n",
      "4088/4088 [==============================] - 1320s 323ms/step - loss: 1.6480 - acc: 0.6659 - val_loss: 1.4144 - val_acc: 0.6161\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.61939\n",
      "Epoch 142/5000\n",
      "4088/4088 [==============================] - 1322s 323ms/step - loss: 1.6365 - acc: 0.6661 - val_loss: 1.4017 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.61939 to 0.62589, saving model to highest_val_acc.h5\n",
      "Epoch 143/5000\n",
      "4088/4088 [==============================] - 1320s 323ms/step - loss: 1.6187 - acc: 0.6709 - val_loss: 1.4123 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.62589\n",
      "Epoch 144/5000\n",
      "4088/4088 [==============================] - 1425s 349ms/step - loss: 1.5911 - acc: 0.6784 - val_loss: 1.3905 - val_acc: 0.6291\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.62589 to 0.62914, saving model to highest_val_acc.h5\n",
      "Epoch 145/5000\n",
      "4088/4088 [==============================] - 1491s 365ms/step - loss: 1.5811 - acc: 0.6800 - val_loss: 1.3671 - val_acc: 0.6244\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.62914\n",
      "Epoch 146/5000\n",
      "4088/4088 [==============================] - 1492s 365ms/step - loss: 1.5740 - acc: 0.6804 - val_loss: 1.3673 - val_acc: 0.6297\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.62914 to 0.62973, saving model to highest_val_acc.h5\n",
      "Epoch 147/5000\n",
      "4088/4088 [==============================] - 1491s 365ms/step - loss: 1.5537 - acc: 0.6852 - val_loss: 1.3768 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.62973\n",
      "Epoch 148/5000\n",
      "4088/4088 [==============================] - 1492s 365ms/step - loss: 1.5435 - acc: 0.6880 - val_loss: 1.3389 - val_acc: 0.6424\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.62973 to 0.64243, saving model to highest_val_acc.h5\n",
      "Epoch 149/5000\n",
      "4088/4088 [==============================] - 1493s 365ms/step - loss: 1.5352 - acc: 0.6896 - val_loss: 1.3625 - val_acc: 0.6297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00149: val_acc did not improve from 0.64243\n",
      "Epoch 150/5000\n",
      "4088/4088 [==============================] - 1629s 398ms/step - loss: 1.5138 - acc: 0.6875 - val_loss: 1.3194 - val_acc: 0.6321\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.64243\n",
      "Epoch 151/5000\n",
      "4088/4088 [==============================] - 1594s 390ms/step - loss: 1.5083 - acc: 0.7009 - val_loss: 1.3203 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.64243\n",
      "Epoch 152/5000\n",
      "4088/4088 [==============================] - 1592s 389ms/step - loss: 1.4951 - acc: 0.6998 - val_loss: 1.3045 - val_acc: 0.6457\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.64243 to 0.64569, saving model to highest_val_acc.h5\n",
      "Epoch 153/5000\n",
      "4088/4088 [==============================] - 1597s 391ms/step - loss: 1.4836 - acc: 0.6993 - val_loss: 1.3027 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.64569\n",
      "Epoch 154/5000\n",
      "4088/4088 [==============================] - 1595s 390ms/step - loss: 1.4647 - acc: 0.7079 - val_loss: 1.2761 - val_acc: 0.6472\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.64569 to 0.64716, saving model to highest_val_acc.h5\n",
      "Epoch 155/5000\n",
      "4088/4088 [==============================] - 1593s 390ms/step - loss: 1.4534 - acc: 0.7069 - val_loss: 1.2778 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.64716 to 0.64894, saving model to highest_val_acc.h5\n",
      "Epoch 156/5000\n",
      "4088/4088 [==============================] - 1593s 390ms/step - loss: 1.4438 - acc: 0.7090 - val_loss: 1.2874 - val_acc: 0.6433\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.64894\n",
      "Epoch 157/5000\n",
      "4088/4088 [==============================] - 1593s 390ms/step - loss: 1.4292 - acc: 0.7118 - val_loss: 1.2601 - val_acc: 0.6528\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.64894 to 0.65278, saving model to highest_val_acc.h5\n",
      "Epoch 158/5000\n",
      "4088/4088 [==============================] - 1590s 389ms/step - loss: 1.4175 - acc: 0.7196 - val_loss: 1.2943 - val_acc: 0.6430\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.65278\n",
      "Epoch 159/5000\n",
      "4088/4088 [==============================] - 1587s 388ms/step - loss: 1.4012 - acc: 0.7182 - val_loss: 1.2220 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.65278 to 0.65987, saving model to highest_val_acc.h5\n",
      "Epoch 160/5000\n",
      "4088/4088 [==============================] - 1598s 391ms/step - loss: 1.3906 - acc: 0.7259 - val_loss: 1.2580 - val_acc: 0.6519\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.65987\n",
      "Epoch 161/5000\n",
      "4088/4088 [==============================] - 1592s 389ms/step - loss: 1.3789 - acc: 0.7266 - val_loss: 1.2439 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.65987\n",
      "Epoch 162/5000\n",
      "4088/4088 [==============================] - 1589s 389ms/step - loss: 1.3734 - acc: 0.7258 - val_loss: 1.2091 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.65987 to 0.66637, saving model to highest_val_acc.h5\n",
      "Epoch 163/5000\n",
      "4088/4088 [==============================] - 1596s 390ms/step - loss: 1.3608 - acc: 0.7295 - val_loss: 1.2298 - val_acc: 0.6616\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.66637\n",
      "Epoch 164/5000\n",
      "4088/4088 [==============================] - 1589s 389ms/step - loss: 1.3444 - acc: 0.7323 - val_loss: 1.2129 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.66637\n",
      "Epoch 165/5000\n",
      "4088/4088 [==============================] - 1592s 389ms/step - loss: 1.3397 - acc: 0.7351 - val_loss: 1.2401 - val_acc: 0.6504\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.66637\n",
      "Epoch 166/5000\n",
      "4088/4088 [==============================] - 1598s 391ms/step - loss: 1.3319 - acc: 0.7388 - val_loss: 1.1815 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.66637 to 0.66667, saving model to highest_val_acc.h5\n",
      "Epoch 167/5000\n",
      "4088/4088 [==============================] - 1592s 390ms/step - loss: 1.3043 - acc: 0.7413 - val_loss: 1.1914 - val_acc: 0.6670\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.66667 to 0.66696, saving model to highest_val_acc.h5\n",
      "Epoch 168/5000\n",
      "4088/4088 [==============================] - 1598s 391ms/step - loss: 1.3000 - acc: 0.7425 - val_loss: 1.1711 - val_acc: 0.6714\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.66696 to 0.67139, saving model to highest_val_acc.h5\n",
      "Epoch 169/5000\n",
      "4088/4088 [==============================] - 1594s 390ms/step - loss: 1.2896 - acc: 0.7482 - val_loss: 1.1931 - val_acc: 0.6646\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.67139\n",
      "Epoch 170/5000\n",
      "4088/4088 [==============================] - 1598s 391ms/step - loss: 1.2747 - acc: 0.7441 - val_loss: 1.1878 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.67139\n",
      "Epoch 171/5000\n",
      " 585/4088 [===>..........................] - ETA: 21:46 - loss: 1.2270 - acc: 0.7618"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9193366bdd96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     class_weight=the_class_weight)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=5000,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9dca8954386b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
