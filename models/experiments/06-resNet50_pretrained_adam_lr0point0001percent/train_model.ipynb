{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_plot_name = \"trainplot.png\"\n",
    "model_name = 'highest_val_acc.h5'\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/herri/.local/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/herri/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=10)\n",
    "\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 5.2180 - acc: 0.0216 - val_loss: 4.9750 - val_acc: 0.0446\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.04462, saving model to highest_val_acc.h5\n",
      "Epoch 2/5000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 4.7512 - acc: 0.0751 - val_loss: 4.4017 - val_acc: 0.0943\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.04462 to 0.09427, saving model to highest_val_acc.h5\n",
      "Epoch 3/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 4.3373 - acc: 0.1470 - val_loss: 3.8980 - val_acc: 0.1554\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.09427 to 0.15544, saving model to highest_val_acc.h5\n",
      "Epoch 4/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 3.9811 - acc: 0.2001 - val_loss: 3.5171 - val_acc: 0.2137\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.15544 to 0.21365, saving model to highest_val_acc.h5\n",
      "Epoch 5/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 3.6784 - acc: 0.2453 - val_loss: 3.1968 - val_acc: 0.2665\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.21365 to 0.26655, saving model to highest_val_acc.h5\n",
      "Epoch 6/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 3.4115 - acc: 0.2969 - val_loss: 2.9152 - val_acc: 0.3144\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.26655 to 0.31442, saving model to highest_val_acc.h5\n",
      "Epoch 7/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 3.1577 - acc: 0.3448 - val_loss: 2.6577 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.31442 to 0.36407, saving model to highest_val_acc.h5\n",
      "Epoch 8/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 2.9338 - acc: 0.3842 - val_loss: 2.4337 - val_acc: 0.4031\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.36407 to 0.40307, saving model to highest_val_acc.h5\n",
      "Epoch 9/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 2.7096 - acc: 0.4359 - val_loss: 2.2089 - val_acc: 0.4530\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.40307 to 0.45301, saving model to highest_val_acc.h5\n",
      "Epoch 10/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 2.5044 - acc: 0.4750 - val_loss: 2.0086 - val_acc: 0.4917\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.45301 to 0.49173, saving model to highest_val_acc.h5\n",
      "Epoch 11/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 2.3064 - acc: 0.5196 - val_loss: 1.8456 - val_acc: 0.5174\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.49173 to 0.51743, saving model to highest_val_acc.h5\n",
      "Epoch 12/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 2.1223 - acc: 0.5600 - val_loss: 1.6915 - val_acc: 0.5538\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.51743 to 0.55378, saving model to highest_val_acc.h5\n",
      "Epoch 13/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 1.9652 - acc: 0.5967 - val_loss: 1.5653 - val_acc: 0.5916\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.55378 to 0.59161, saving model to highest_val_acc.h5\n",
      "Epoch 14/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 1.7976 - acc: 0.6326 - val_loss: 1.4441 - val_acc: 0.6108\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.59161 to 0.61082, saving model to highest_val_acc.h5\n",
      "Epoch 15/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 1.6649 - acc: 0.6606 - val_loss: 1.3271 - val_acc: 0.6318\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.61082 to 0.63180, saving model to highest_val_acc.h5\n",
      "Epoch 16/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 1.5220 - acc: 0.6961 - val_loss: 1.2685 - val_acc: 0.6401\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.63180 to 0.64007, saving model to highest_val_acc.h5\n",
      "Epoch 17/5000\n",
      "4088/4088 [==============================] - 482s 118ms/step - loss: 1.4073 - acc: 0.7158 - val_loss: 1.1698 - val_acc: 0.6649\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.64007 to 0.66489, saving model to highest_val_acc.h5\n",
      "Epoch 18/5000\n",
      "4088/4088 [==============================] - 485s 119ms/step - loss: 1.2978 - acc: 0.7398 - val_loss: 1.1047 - val_acc: 0.6791\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.66489 to 0.67908, saving model to highest_val_acc.h5\n",
      "Epoch 19/5000\n",
      "4088/4088 [==============================] - 502s 123ms/step - loss: 1.1883 - acc: 0.7674 - val_loss: 1.0409 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.67908 to 0.69415, saving model to highest_val_acc.h5\n",
      "Epoch 20/5000\n",
      "4088/4088 [==============================] - 502s 123ms/step - loss: 1.0911 - acc: 0.7871 - val_loss: 0.9810 - val_acc: 0.7086\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.69415 to 0.70863, saving model to highest_val_acc.h5\n",
      "Epoch 21/5000\n",
      "4088/4088 [==============================] - 502s 123ms/step - loss: 0.9976 - acc: 0.8115 - val_loss: 0.9365 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.70863 to 0.72281, saving model to highest_val_acc.h5\n",
      "Epoch 22/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 0.9196 - acc: 0.8241 - val_loss: 0.8977 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.72281 to 0.72813, saving model to highest_val_acc.h5\n",
      "Epoch 23/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 0.8448 - acc: 0.8456 - val_loss: 0.8576 - val_acc: 0.7435\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.72813 to 0.74350, saving model to highest_val_acc.h5\n",
      "Epoch 24/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 0.7802 - acc: 0.8564 - val_loss: 0.8360 - val_acc: 0.7479\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.74350 to 0.74793, saving model to highest_val_acc.h5\n",
      "Epoch 25/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 0.7089 - acc: 0.8716 - val_loss: 0.8034 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.74793 to 0.76123, saving model to highest_val_acc.h5\n",
      "Epoch 26/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 0.6605 - acc: 0.8849 - val_loss: 0.7859 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.76123 to 0.76418, saving model to highest_val_acc.h5\n",
      "Epoch 27/5000\n",
      "4088/4088 [==============================] - 487s 119ms/step - loss: 0.5952 - acc: 0.8962 - val_loss: 0.7627 - val_acc: 0.7722\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.76418 to 0.77216, saving model to highest_val_acc.h5\n",
      "Epoch 28/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.5563 - acc: 0.9063 - val_loss: 0.7561 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.77216 to 0.77541, saving model to highest_val_acc.h5\n",
      "Epoch 29/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.5095 - acc: 0.9181 - val_loss: 0.7418 - val_acc: 0.7896\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.77541 to 0.78960, saving model to highest_val_acc.h5\n",
      "Epoch 30/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.4630 - acc: 0.9274 - val_loss: 0.7118 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.78960 to 0.79167, saving model to highest_val_acc.h5\n",
      "Epoch 31/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.4223 - acc: 0.9337 - val_loss: 0.6960 - val_acc: 0.8002\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.79167 to 0.80024, saving model to highest_val_acc.h5\n",
      "Epoch 32/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.3931 - acc: 0.9399 - val_loss: 0.7046 - val_acc: 0.7979\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80024\n",
      "Epoch 33/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.3594 - acc: 0.9482 - val_loss: 0.7000 - val_acc: 0.7988\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.80024\n",
      "Epoch 34/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.3247 - acc: 0.9571 - val_loss: 0.6827 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.80024 to 0.80822, saving model to highest_val_acc.h5\n",
      "Epoch 35/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.2954 - acc: 0.9622 - val_loss: 0.6976 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.80822\n",
      "Epoch 36/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.2667 - acc: 0.9665 - val_loss: 0.6860 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.80822 to 0.81413, saving model to highest_val_acc.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.2441 - acc: 0.9709 - val_loss: 0.6763 - val_acc: 0.8126\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.81413\n",
      "Epoch 38/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.2234 - acc: 0.9760 - val_loss: 0.6655 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.81413 to 0.81856, saving model to highest_val_acc.h5\n",
      "Epoch 39/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.2030 - acc: 0.9793 - val_loss: 0.6732 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.81856\n",
      "Epoch 40/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.1820 - acc: 0.9817 - val_loss: 0.6945 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.81856\n",
      "Epoch 41/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.1661 - acc: 0.9852 - val_loss: 0.6901 - val_acc: 0.8159\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.81856\n",
      "Epoch 42/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.1495 - acc: 0.9861 - val_loss: 0.6759 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.81856 to 0.82181, saving model to highest_val_acc.h5\n",
      "Epoch 43/5000\n",
      "4088/4088 [==============================] - 474s 116ms/step - loss: 0.1355 - acc: 0.9896 - val_loss: 0.6970 - val_acc: 0.8212\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.82181\n",
      "Epoch 44/5000\n",
      "4088/4088 [==============================] - 484s 118ms/step - loss: 0.1239 - acc: 0.9910 - val_loss: 0.7083 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.82181\n",
      "Epoch 45/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.1133 - acc: 0.9922 - val_loss: 0.7065 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.82181\n",
      "Epoch 46/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0994 - acc: 0.9934 - val_loss: 0.7131 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.82181 to 0.82535, saving model to highest_val_acc.h5\n",
      "Epoch 47/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0944 - acc: 0.9936 - val_loss: 0.7236 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.82535\n",
      "Epoch 48/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0832 - acc: 0.9948 - val_loss: 0.7115 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.82535 to 0.83452, saving model to highest_val_acc.h5\n",
      "Epoch 49/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0730 - acc: 0.9961 - val_loss: 0.7299 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.83452\n",
      "Epoch 50/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0684 - acc: 0.9958 - val_loss: 0.7256 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.83452\n",
      "Epoch 51/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0594 - acc: 0.9977 - val_loss: 0.7300 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.83452\n",
      "Epoch 52/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0552 - acc: 0.9975 - val_loss: 0.7488 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.83452\n",
      "Epoch 53/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0496 - acc: 0.9976 - val_loss: 0.7454 - val_acc: 0.8298\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.83452\n",
      "Epoch 54/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0468 - acc: 0.9977 - val_loss: 0.7213 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.83452\n",
      "Epoch 55/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0413 - acc: 0.9977 - val_loss: 0.7413 - val_acc: 0.8336\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.83452\n",
      "Epoch 56/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0368 - acc: 0.9988 - val_loss: 0.7740 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.83452\n",
      "Epoch 57/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0362 - acc: 0.9983 - val_loss: 0.8190 - val_acc: 0.8209\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.83452\n",
      "Epoch 58/5000\n",
      "4088/4088 [==============================] - 488s 119ms/step - loss: 0.0312 - acc: 0.9987 - val_loss: 0.7482 - val_acc: 0.8345\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.83452\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=5000,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
