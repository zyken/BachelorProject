{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.estimator package not installed.\n",
      "tf.estimator package not installed.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_plot_name = \"trainplot.png\"\n",
    "model_name = 'highest_val_acc.h5'\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=4)\n",
    "\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4088/4088 [==============================] - 717s 175ms/step - loss: 3.8063 - acc: 0.2158 - val_loss: 2.2179 - val_acc: 0.4214\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42139, saving model to highest_val_acc.h5\n",
      "Epoch 2/50\n",
      "4088/4088 [==============================] - 721s 176ms/step - loss: 1.9844 - acc: 0.5269 - val_loss: 1.3342 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.42139 to 0.62589, saving model to highest_val_acc.h5\n",
      "Epoch 3/50\n",
      "4088/4088 [==============================] - 697s 170ms/step - loss: 1.1489 - acc: 0.7144 - val_loss: 0.8580 - val_acc: 0.7337\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.62589 to 0.73375, saving model to highest_val_acc.h5\n",
      "Epoch 4/50\n",
      "4088/4088 [==============================] - 711s 174ms/step - loss: 0.7404 - acc: 0.8187 - val_loss: 0.8634 - val_acc: 0.7385\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73375 to 0.73848, saving model to highest_val_acc.h5\n",
      "Epoch 5/50\n",
      "4088/4088 [==============================] - 703s 172ms/step - loss: 0.5034 - acc: 0.8821 - val_loss: 0.7765 - val_acc: 0.7858\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.73848 to 0.78576, saving model to highest_val_acc.h5\n",
      "Epoch 6/50\n",
      "4088/4088 [==============================] - 699s 171ms/step - loss: 0.3562 - acc: 0.9198 - val_loss: 0.6982 - val_acc: 0.8112\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.78576 to 0.81117, saving model to highest_val_acc.h5\n",
      "Epoch 7/50\n",
      "4088/4088 [==============================] - 714s 175ms/step - loss: 0.2561 - acc: 0.9481 - val_loss: 0.7354 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81117 to 0.81176, saving model to highest_val_acc.h5\n",
      "Epoch 8/50\n",
      "4088/4088 [==============================] - 696s 170ms/step - loss: 0.1815 - acc: 0.9658 - val_loss: 0.7213 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.81176 to 0.82417, saving model to highest_val_acc.h5\n",
      "Epoch 9/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 0.1261 - acc: 0.9812 - val_loss: 0.7090 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.82417 to 0.82949, saving model to highest_val_acc.h5\n",
      "Epoch 10/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 0.0953 - acc: 0.9872 - val_loss: 0.7592 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.82949\n",
      "Epoch 11/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 0.0746 - acc: 0.9905 - val_loss: 0.7196 - val_acc: 0.8366\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.82949 to 0.83658, saving model to highest_val_acc.h5\n",
      "Epoch 12/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 0.0610 - acc: 0.9931 - val_loss: 0.7045 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.83658 to 0.84634, saving model to highest_val_acc.h5\n",
      "Epoch 13/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 0.0486 - acc: 0.9954 - val_loss: 0.7348 - val_acc: 0.8348\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.84634\n",
      "Epoch 14/50\n",
      "4088/4088 [==============================] - 676s 165ms/step - loss: 0.0413 - acc: 0.9962 - val_loss: 0.7453 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.84634\n",
      "Epoch 15/50\n",
      "4088/4088 [==============================] - 677s 166ms/step - loss: 0.0306 - acc: 0.9979 - val_loss: 0.8038 - val_acc: 0.8357\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.84634\n",
      "Epoch 16/50\n",
      "4088/4088 [==============================] - 677s 166ms/step - loss: 0.0281 - acc: 0.9977 - val_loss: 0.7385 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.84634 to 0.84752, saving model to highest_val_acc.h5\n",
      "Epoch 17/50\n",
      "4088/4088 [==============================] - 676s 165ms/step - loss: 0.0247 - acc: 0.9977 - val_loss: 0.7657 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84752\n",
      "Epoch 18/50\n",
      "4088/4088 [==============================] - 676s 165ms/step - loss: 0.0201 - acc: 0.9988 - val_loss: 0.8070 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.84752\n",
      "Epoch 19/50\n",
      "4088/4088 [==============================] - 677s 166ms/step - loss: 0.0225 - acc: 0.9977 - val_loss: 0.7901 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.84752\n",
      "Epoch 20/50\n",
      "4088/4088 [==============================] - 676s 165ms/step - loss: 0.0185 - acc: 0.9986 - val_loss: 0.7892 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.84752 to 0.85047, saving model to highest_val_acc.h5\n",
      "Epoch 21/50\n",
      "4088/4088 [==============================] - 677s 166ms/step - loss: 0.0182 - acc: 0.9986 - val_loss: 0.7657 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.85047 to 0.85668, saving model to highest_val_acc.h5\n",
      "Epoch 22/50\n",
      "4088/4088 [==============================] - 677s 166ms/step - loss: 0.0188 - acc: 0.9981 - val_loss: 0.8266 - val_acc: 0.8425\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.85668\n",
      "Epoch 23/50\n",
      "4088/4088 [==============================] - 675s 165ms/step - loss: 0.0175 - acc: 0.9988 - val_loss: 0.8181 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.85668\n",
      "Epoch 24/50\n",
      "4088/4088 [==============================] - 675s 165ms/step - loss: 0.0155 - acc: 0.9981 - val_loss: 0.7558 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.85668\n",
      "Epoch 25/50\n",
      "4088/4088 [==============================] - 676s 165ms/step - loss: 0.0145 - acc: 0.9989 - val_loss: 0.7542 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.85668 to 0.85786, saving model to highest_val_acc.h5\n",
      "Epoch 26/50\n",
      "4088/4088 [==============================] - 680s 166ms/step - loss: 0.0110 - acc: 0.9992 - val_loss: 0.7888 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.85786\n",
      "Epoch 27/50\n",
      "4088/4088 [==============================] - 715s 175ms/step - loss: 0.0122 - acc: 0.9989 - val_loss: 0.7725 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.85786\n",
      "Epoch 28/50\n",
      "4088/4088 [==============================] - 700s 171ms/step - loss: 0.0124 - acc: 0.9988 - val_loss: 0.8887 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.85786\n",
      "Epoch 29/50\n",
      "4088/4088 [==============================] - 707s 173ms/step - loss: 0.0106 - acc: 0.9991 - val_loss: 0.8403 - val_acc: 0.8496\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.85786\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxoRYUjDGGBNiScEYY0yIJQVjjDEh/x+SyK/Ti/A39QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fde45ca2910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
