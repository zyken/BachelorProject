{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.estimator package not installed.\n",
      "tf.estimator package not installed.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_plot_name = \"trainplot.png\"\n",
    "model_name = 'highest_val_acc.h5'\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.1, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=4)\n",
    "\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4088/4088 [==============================] - 715s 175ms/step - loss: 3.7270 - acc: 0.1616 - val_loss: 3.9183 - val_acc: 0.1791\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.17908, saving model to highest_val_acc.h5\n",
      "Epoch 2/50\n",
      "4088/4088 [==============================] - 708s 173ms/step - loss: 1.6830 - acc: 0.5130 - val_loss: 3.3121 - val_acc: 0.3230\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.17908 to 0.32299, saving model to highest_val_acc.h5\n",
      "Epoch 3/50\n",
      "4088/4088 [==============================] - 680s 166ms/step - loss: 0.9661 - acc: 0.7078 - val_loss: 1.4404 - val_acc: 0.5966\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.32299 to 0.59663, saving model to highest_val_acc.h5\n",
      "Epoch 4/50\n",
      "4088/4088 [==============================] - 675s 165ms/step - loss: 0.6400 - acc: 0.8031 - val_loss: 1.7211 - val_acc: 0.6079\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.59663 to 0.60786, saving model to highest_val_acc.h5\n",
      "Epoch 5/50\n",
      "4088/4088 [==============================] - 675s 165ms/step - loss: 0.4358 - acc: 0.8633 - val_loss: 1.4466 - val_acc: 0.6507\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.60786 to 0.65071, saving model to highest_val_acc.h5\n",
      "Epoch 6/50\n",
      "4088/4088 [==============================] - 676s 165ms/step - loss: 0.3061 - acc: 0.9026 - val_loss: 1.0642 - val_acc: 0.7225\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.65071 to 0.72252, saving model to highest_val_acc.h5\n",
      "Epoch 7/50\n",
      "4088/4088 [==============================] - 675s 165ms/step - loss: 0.2060 - acc: 0.9376 - val_loss: 1.1055 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72252 to 0.74498, saving model to highest_val_acc.h5\n",
      "Epoch 8/50\n",
      "4088/4088 [==============================] - 675s 165ms/step - loss: 0.1466 - acc: 0.9524 - val_loss: 1.0634 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74498 to 0.74911, saving model to highest_val_acc.h5\n",
      "Epoch 9/50\n",
      "4088/4088 [==============================] - 673s 165ms/step - loss: 0.0911 - acc: 0.9747 - val_loss: 1.2158 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.74911 to 0.75621, saving model to highest_val_acc.h5\n",
      "Epoch 10/50\n",
      "4088/4088 [==============================] - 673s 165ms/step - loss: 0.0583 - acc: 0.9836 - val_loss: 1.1217 - val_acc: 0.7713\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.75621 to 0.77128, saving model to highest_val_acc.h5\n",
      "Epoch 11/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 0.0489 - acc: 0.9869 - val_loss: 0.9002 - val_acc: 0.7988\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.77128 to 0.79876, saving model to highest_val_acc.h5\n",
      "Epoch 12/50\n",
      "4088/4088 [==============================] - 699s 171ms/step - loss: 0.0298 - acc: 0.9918 - val_loss: 1.4345 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.79876\n",
      "Epoch 13/50\n",
      "4088/4088 [==============================] - 715s 175ms/step - loss: 0.0418 - acc: 0.9868 - val_loss: 1.2125 - val_acc: 0.7663\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.79876\n",
      "Epoch 14/50\n",
      "4088/4088 [==============================] - 719s 176ms/step - loss: 0.0217 - acc: 0.9952 - val_loss: 1.3134 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.79876\n",
      "Epoch 15/50\n",
      "4088/4088 [==============================] - 709s 173ms/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.9310 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.79876 to 0.81501, saving model to highest_val_acc.h5\n",
      "Epoch 16/50\n",
      "4088/4088 [==============================] - 728s 178ms/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.8816 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.81501 to 0.82772, saving model to highest_val_acc.h5\n",
      "Epoch 17/50\n",
      "4088/4088 [==============================] - 711s 174ms/step - loss: 0.0074 - acc: 0.9989 - val_loss: 0.9317 - val_acc: 0.8221\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.82772\n",
      "Epoch 18/50\n",
      "4088/4088 [==============================] - 689s 169ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.8995 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.82772 to 0.83186, saving model to highest_val_acc.h5\n",
      "Epoch 19/50\n",
      "4088/4088 [==============================] - 707s 173ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 1.1122 - val_acc: 0.7689\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.83186\n",
      "Epoch 20/50\n",
      "4088/4088 [==============================] - 749s 183ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.8971 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.83186\n",
      "Epoch 21/50\n",
      "4088/4088 [==============================] - 816s 200ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9718 - val_acc: 0.8324\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.83186 to 0.83245, saving model to highest_val_acc.h5\n",
      "Epoch 22/50\n",
      "4088/4088 [==============================] - 740s 181ms/step - loss: 7.8116e-04 - acc: 1.0000 - val_loss: 0.9834 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.83245 to 0.83304, saving model to highest_val_acc.h5\n",
      "Epoch 23/50\n",
      "4088/4088 [==============================] - 734s 180ms/step - loss: 6.2893e-04 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.83304 to 0.83422, saving model to highest_val_acc.h5\n",
      "Epoch 24/50\n",
      "4088/4088 [==============================] - 711s 174ms/step - loss: 6.0449e-04 - acc: 1.0000 - val_loss: 0.9526 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.83422 to 0.83954, saving model to highest_val_acc.h5\n",
      "Epoch 25/50\n",
      "4088/4088 [==============================] - 713s 174ms/step - loss: 4.7454e-04 - acc: 1.0000 - val_loss: 1.0414 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.83954\n",
      "Epoch 26/50\n",
      "4088/4088 [==============================] - 710s 174ms/step - loss: 4.2432e-04 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83954\n",
      "Epoch 27/50\n",
      "4088/4088 [==============================] - 702s 172ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.9670 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83954\n",
      "Epoch 28/50\n",
      "4088/4088 [==============================] - 752s 184ms/step - loss: 5.9452e-04 - acc: 1.0000 - val_loss: 0.9558 - val_acc: 0.8372\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.83954\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nykGTglJKKQdNCkoppRw0KSillHL4f5F3983P5mpHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3967b31b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
