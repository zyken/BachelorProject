{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_plot_name = \"trainplot.png\"\n",
    "model_name = 'highest_val_acc.h5'\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/herri/.local/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/herri/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=10)\n",
    "\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500000\n",
      "4088/4088 [==============================] - 484s 118ms/step - loss: 5.7248 - acc: 0.0294 - val_loss: 4.7677 - val_acc: 0.0514\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.05142, saving model to highest_val_acc.h5\n",
      "Epoch 2/500000\n",
      "4088/4088 [==============================] - 477s 117ms/step - loss: 4.2875 - acc: 0.0938 - val_loss: 4.8926 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.05142 to 0.11348, saving model to highest_val_acc.h5\n",
      "Epoch 3/500000\n",
      "4088/4088 [==============================] - 483s 118ms/step - loss: 3.5221 - acc: 0.1807 - val_loss: 3.3453 - val_acc: 0.1974\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.11348 to 0.19740, saving model to highest_val_acc.h5\n",
      "Epoch 4/500000\n",
      "4088/4088 [==============================] - 486s 119ms/step - loss: 2.7738 - acc: 0.2967 - val_loss: 2.8673 - val_acc: 0.2739\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.19740 to 0.27394, saving model to highest_val_acc.h5\n",
      "Epoch 5/500000\n",
      "4088/4088 [==============================] - 491s 120ms/step - loss: 2.2453 - acc: 0.3960 - val_loss: 2.5268 - val_acc: 0.3587\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.27394 to 0.35875, saving model to highest_val_acc.h5\n",
      "Epoch 6/500000\n",
      "4088/4088 [==============================] - 493s 121ms/step - loss: 1.8946 - acc: 0.4725 - val_loss: 1.9067 - val_acc: 0.4696\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.35875 to 0.46956, saving model to highest_val_acc.h5\n",
      "Epoch 7/500000\n",
      "4088/4088 [==============================] - 497s 122ms/step - loss: 1.6384 - acc: 0.5285 - val_loss: 2.0577 - val_acc: 0.4702\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.46956 to 0.47015, saving model to highest_val_acc.h5\n",
      "Epoch 8/500000\n",
      "4088/4088 [==============================] - 498s 122ms/step - loss: 1.4336 - acc: 0.5782 - val_loss: 2.0093 - val_acc: 0.4391\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.47015\n",
      "Epoch 9/500000\n",
      "4088/4088 [==============================] - 500s 122ms/step - loss: 1.2684 - acc: 0.6263 - val_loss: 1.4905 - val_acc: 0.5626\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.47015 to 0.56265, saving model to highest_val_acc.h5\n",
      "Epoch 10/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 1.1253 - acc: 0.6566 - val_loss: 1.7201 - val_acc: 0.5358\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.56265\n",
      "Epoch 11/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 1.0310 - acc: 0.6840 - val_loss: 1.6411 - val_acc: 0.5461\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.56265\n",
      "Epoch 12/500000\n",
      "4088/4088 [==============================] - 503s 123ms/step - loss: 0.9408 - acc: 0.7085 - val_loss: 1.6214 - val_acc: 0.5683\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.56265 to 0.56826, saving model to highest_val_acc.h5\n",
      "Epoch 13/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.8600 - acc: 0.7307 - val_loss: 1.6265 - val_acc: 0.5830\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.56826 to 0.58304, saving model to highest_val_acc.h5\n",
      "Epoch 14/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.7968 - acc: 0.7542 - val_loss: 2.4483 - val_acc: 0.4601\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58304\n",
      "Epoch 15/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.7350 - acc: 0.7640 - val_loss: 1.7656 - val_acc: 0.5624\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58304\n",
      "Epoch 16/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.6764 - acc: 0.7859 - val_loss: 1.8113 - val_acc: 0.5547\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.58304\n",
      "Epoch 17/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.6358 - acc: 0.7987 - val_loss: 1.6825 - val_acc: 0.5780\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.58304\n",
      "Epoch 18/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.5874 - acc: 0.8108 - val_loss: 1.4965 - val_acc: 0.6150\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.58304 to 0.61495, saving model to highest_val_acc.h5\n",
      "Epoch 19/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.5417 - acc: 0.8301 - val_loss: 1.3485 - val_acc: 0.6439\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.61495 to 0.64391, saving model to highest_val_acc.h5\n",
      "Epoch 20/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.5075 - acc: 0.8346 - val_loss: 1.3246 - val_acc: 0.6507\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.64391 to 0.65071, saving model to highest_val_acc.h5\n",
      "Epoch 21/500000\n",
      "4088/4088 [==============================] - 504s 123ms/step - loss: 0.4729 - acc: 0.8443 - val_loss: 1.7552 - val_acc: 0.5712\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.65071\n",
      "Epoch 22/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.4317 - acc: 0.8600 - val_loss: 1.5197 - val_acc: 0.6522\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.65071 to 0.65219, saving model to highest_val_acc.h5\n",
      "Epoch 23/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.4115 - acc: 0.8663 - val_loss: 1.5282 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.65219\n",
      "Epoch 24/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.4002 - acc: 0.8726 - val_loss: 1.7747 - val_acc: 0.6064\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.65219\n",
      "Epoch 25/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.3576 - acc: 0.8832 - val_loss: 1.5111 - val_acc: 0.6687\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.65219 to 0.66874, saving model to highest_val_acc.h5\n",
      "Epoch 26/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.3445 - acc: 0.8876 - val_loss: 3.0494 - val_acc: 0.5207\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.66874\n",
      "Epoch 27/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.3205 - acc: 0.8964 - val_loss: 1.6056 - val_acc: 0.6554\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.66874\n",
      "Epoch 28/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.3185 - acc: 0.8984 - val_loss: 1.6141 - val_acc: 0.6696\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.66874 to 0.66962, saving model to highest_val_acc.h5\n",
      "Epoch 29/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2936 - acc: 0.9070 - val_loss: 1.6991 - val_acc: 0.6353\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.66962\n",
      "Epoch 30/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2760 - acc: 0.9081 - val_loss: 2.3847 - val_acc: 0.5922\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.66962\n",
      "Epoch 31/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2593 - acc: 0.9170 - val_loss: 1.7749 - val_acc: 0.6330\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.66962\n",
      "Epoch 32/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2623 - acc: 0.9130 - val_loss: 1.5327 - val_acc: 0.6782\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.66962 to 0.67819, saving model to highest_val_acc.h5\n",
      "Epoch 33/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2413 - acc: 0.9194 - val_loss: 1.9446 - val_acc: 0.6451\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.67819\n",
      "Epoch 34/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2275 - acc: 0.9251 - val_loss: 1.5842 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.67819\n",
      "Epoch 35/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2223 - acc: 0.9291 - val_loss: 1.5853 - val_acc: 0.6859\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.67819 to 0.68587, saving model to highest_val_acc.h5\n",
      "Epoch 36/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2206 - acc: 0.9292 - val_loss: 1.7543 - val_acc: 0.6794\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.68587\n",
      "Epoch 37/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2171 - acc: 0.9306 - val_loss: 1.9479 - val_acc: 0.6483\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.68587\n",
      "Epoch 38/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2187 - acc: 0.9277 - val_loss: 1.9667 - val_acc: 0.6478\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.68587\n",
      "Epoch 39/500000\n",
      "4088/4088 [==============================] - 489s 120ms/step - loss: 0.2103 - acc: 0.9327 - val_loss: 1.6709 - val_acc: 0.6809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_acc did not improve from 0.68587\n",
      "Epoch 40/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1938 - acc: 0.9407 - val_loss: 1.7532 - val_acc: 0.6859\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.68587 to 0.68587, saving model to highest_val_acc.h5\n",
      "Epoch 41/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1859 - acc: 0.9429 - val_loss: 1.7891 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.68587\n",
      "Epoch 42/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1747 - acc: 0.9438 - val_loss: 1.8267 - val_acc: 0.6755\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.68587\n",
      "Epoch 43/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1810 - acc: 0.9390 - val_loss: 1.7649 - val_acc: 0.6678\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.68587\n",
      "Epoch 44/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1725 - acc: 0.9447 - val_loss: 2.1182 - val_acc: 0.6362\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.68587\n",
      "Epoch 45/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1715 - acc: 0.9453 - val_loss: 2.0008 - val_acc: 0.6548\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.68587\n",
      "Epoch 46/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1727 - acc: 0.9453 - val_loss: 2.2657 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.68587\n",
      "Epoch 47/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1665 - acc: 0.9496 - val_loss: 2.3051 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.68587\n",
      "Epoch 48/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1689 - acc: 0.9494 - val_loss: 2.0537 - val_acc: 0.6501\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.68587\n",
      "Epoch 49/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1413 - acc: 0.9535 - val_loss: 2.5008 - val_acc: 0.6194\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.68587\n",
      "Epoch 50/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1623 - acc: 0.9500 - val_loss: 2.0808 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.68587 to 0.69533, saving model to highest_val_acc.h5\n",
      "Epoch 51/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1708 - acc: 0.9494 - val_loss: 2.4902 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.69533\n",
      "Epoch 52/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1659 - acc: 0.9519 - val_loss: 2.9349 - val_acc: 0.5848\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.69533\n",
      "Epoch 53/500000\n",
      "4088/4088 [==============================] - 476s 117ms/step - loss: 0.1653 - acc: 0.9498 - val_loss: 2.5282 - val_acc: 0.6356\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.69533\n",
      "Epoch 54/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1427 - acc: 0.9569 - val_loss: 3.5726 - val_acc: 0.5836\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.69533\n",
      "Epoch 55/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1524 - acc: 0.9541 - val_loss: 2.4843 - val_acc: 0.6501\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.69533\n",
      "Epoch 56/500000\n",
      "4088/4088 [==============================] - 476s 116ms/step - loss: 0.1394 - acc: 0.9581 - val_loss: 2.3048 - val_acc: 0.6389\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.69533\n",
      "Epoch 57/500000\n",
      "4088/4088 [==============================] - 479s 117ms/step - loss: 0.1440 - acc: 0.9574 - val_loss: 2.0387 - val_acc: 0.6906\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.69533\n",
      "Epoch 58/500000\n",
      "4088/4088 [==============================] - 490s 120ms/step - loss: 0.1483 - acc: 0.9568 - val_loss: 2.6651 - val_acc: 0.6540\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.69533\n",
      "Epoch 59/500000\n",
      "4088/4088 [==============================] - 490s 120ms/step - loss: 0.1441 - acc: 0.9601 - val_loss: 2.4455 - val_acc: 0.6729\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.69533\n",
      "Epoch 60/500000\n",
      "4088/4088 [==============================] - 490s 120ms/step - loss: 0.1427 - acc: 0.9561 - val_loss: 2.5257 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.69533\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=500000,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
