{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.estimator package not installed.\n",
      "tf.estimator package not installed.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_plot_name = \"trainplot.png\"\n",
    "model_name = 'highest_val_acc.h5'\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, kernel_regularizer=l2(0.1), activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=1)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=10)\n",
    "\n",
    "callbacks = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4088/4088 [==============================] - 1011s 247ms/step - loss: 6.2251 - acc: 0.2155 - val_loss: 4.2628 - val_acc: 0.3700\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36998, saving model to highest_val_acc.h5\n",
      "Epoch 2/50\n",
      "4088/4088 [==============================] - 1041s 255ms/step - loss: 3.1344 - acc: 0.4028 - val_loss: 4.3684 - val_acc: 0.3871\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.36998 to 0.38712, saving model to highest_val_acc.h5\n",
      "Epoch 3/50\n",
      "4088/4088 [==============================] - 801s 196ms/step - loss: 2.7870 - acc: 0.4865 - val_loss: 4.3471 - val_acc: 0.4625\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.38712 to 0.46247, saving model to highest_val_acc.h5\n",
      "Epoch 4/50\n",
      "4088/4088 [==============================] - 685s 168ms/step - loss: 2.5486 - acc: 0.5499 - val_loss: 4.8687 - val_acc: 0.4625\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.46247\n",
      "Epoch 5/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 2.4014 - acc: 0.5861 - val_loss: 3.7145 - val_acc: 0.5491\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.46247 to 0.54905, saving model to highest_val_acc.h5\n",
      "Epoch 6/50\n",
      "4088/4088 [==============================] - 686s 168ms/step - loss: 2.2756 - acc: 0.6169 - val_loss: 4.3097 - val_acc: 0.5186\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.54905\n",
      "Epoch 7/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 2.1902 - acc: 0.6380 - val_loss: 3.8676 - val_acc: 0.5689\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.54905 to 0.56885, saving model to highest_val_acc.h5\n",
      "Epoch 8/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 2.0481 - acc: 0.6756 - val_loss: 3.8408 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.56885 to 0.57033, saving model to highest_val_acc.h5\n",
      "Epoch 9/50\n",
      "4088/4088 [==============================] - 680s 166ms/step - loss: 1.9461 - acc: 0.7017 - val_loss: 3.8716 - val_acc: 0.6158\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.57033 to 0.61584, saving model to highest_val_acc.h5\n",
      "Epoch 10/50\n",
      "4088/4088 [==============================] - 723s 177ms/step - loss: 1.8853 - acc: 0.7206 - val_loss: 4.2247 - val_acc: 0.5999\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.61584\n",
      "Epoch 11/50\n",
      "4088/4088 [==============================] - 713s 175ms/step - loss: 1.8656 - acc: 0.7267 - val_loss: 3.5582 - val_acc: 0.6557\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.61584 to 0.65573, saving model to highest_val_acc.h5\n",
      "Epoch 12/50\n",
      "4088/4088 [==============================] - 688s 168ms/step - loss: 1.8279 - acc: 0.7312 - val_loss: 3.9065 - val_acc: 0.6303\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.65573\n",
      "Epoch 13/50\n",
      "4088/4088 [==============================] - 691s 169ms/step - loss: 1.7639 - acc: 0.7535 - val_loss: 4.5857 - val_acc: 0.5712\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.65573\n",
      "Epoch 14/50\n",
      "4088/4088 [==============================] - 806s 197ms/step - loss: 1.6918 - acc: 0.7692 - val_loss: 3.3831 - val_acc: 0.6992\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.65573 to 0.69917, saving model to highest_val_acc.h5\n",
      "Epoch 15/50\n",
      "4088/4088 [==============================] - 699s 171ms/step - loss: 1.6483 - acc: 0.7807 - val_loss: 3.4715 - val_acc: 0.6649\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.69917\n",
      "Epoch 16/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 1.6392 - acc: 0.7847 - val_loss: 3.6489 - val_acc: 0.6767\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.69917\n",
      "Epoch 17/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.5854 - acc: 0.7971 - val_loss: 4.1956 - val_acc: 0.6061\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.69917\n",
      "Epoch 18/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 1.5883 - acc: 0.7983 - val_loss: 3.2058 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.69917 to 0.70892, saving model to highest_val_acc.h5\n",
      "Epoch 19/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 1.5063 - acc: 0.8131 - val_loss: 3.1523 - val_acc: 0.6906\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.70892\n",
      "Epoch 20/50\n",
      "4088/4088 [==============================] - 679s 166ms/step - loss: 1.4243 - acc: 0.8302 - val_loss: 3.2025 - val_acc: 0.7181\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.70892 to 0.71809, saving model to highest_val_acc.h5\n",
      "Epoch 21/50\n",
      "4088/4088 [==============================] - 680s 166ms/step - loss: 1.4465 - acc: 0.8302 - val_loss: 3.5488 - val_acc: 0.6696\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.71809\n",
      "Epoch 22/50\n",
      "4088/4088 [==============================] - 680s 166ms/step - loss: 1.4771 - acc: 0.8257 - val_loss: 4.1940 - val_acc: 0.6256\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.71809\n",
      "Epoch 23/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.4693 - acc: 0.8265 - val_loss: 3.8820 - val_acc: 0.6353\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.71809\n",
      "Epoch 24/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.4682 - acc: 0.8253 - val_loss: 3.3669 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.71809\n",
      "Epoch 25/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.3805 - acc: 0.8430 - val_loss: 3.0136 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.71809 to 0.73109, saving model to highest_val_acc.h5\n",
      "Epoch 26/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.3483 - acc: 0.8535 - val_loss: 2.7177 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.73109 to 0.76152, saving model to highest_val_acc.h5\n",
      "Epoch 27/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.3429 - acc: 0.8531 - val_loss: 2.8635 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.76152\n",
      "Epoch 28/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.2824 - acc: 0.8635 - val_loss: 2.9179 - val_acc: 0.7580\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.76152\n",
      "Epoch 29/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.1747 - acc: 0.8877 - val_loss: 2.8197 - val_acc: 0.7663\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.76152 to 0.76625, saving model to highest_val_acc.h5\n",
      "Epoch 30/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.1995 - acc: 0.8839 - val_loss: 2.8317 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.76625\n",
      "Epoch 31/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.3237 - acc: 0.8579 - val_loss: 3.2619 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.76625\n",
      "Epoch 32/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.2735 - acc: 0.8716 - val_loss: 2.9057 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.76625\n",
      "Epoch 33/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.2669 - acc: 0.8684 - val_loss: 2.8312 - val_acc: 0.7482\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.76625\n",
      "Epoch 34/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.1803 - acc: 0.8872 - val_loss: 2.9865 - val_acc: 0.7252\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.76625\n",
      "Epoch 35/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.1709 - acc: 0.8885 - val_loss: 2.9074 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.76625\n",
      "Epoch 36/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.1627 - acc: 0.8910 - val_loss: 3.0837 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.76625\n",
      "Epoch 37/50\n",
      "4088/4088 [==============================] - 678s 166ms/step - loss: 1.1952 - acc: 0.8844 - val_loss: 3.3720 - val_acc: 0.6646\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.76625\n",
      "Epoch 38/50\n",
      "4088/4088 [==============================] - 683s 167ms/step - loss: 1.1113 - acc: 0.9004 - val_loss: 7.3211 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.76625\n",
      "Epoch 39/50\n",
      "4088/4088 [==============================] - 697s 170ms/step - loss: 1.0229 - acc: 0.9201 - val_loss: 2.6466 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.76625 to 0.76773, saving model to highest_val_acc.h5\n",
      "Epoch 40/50\n",
      "4088/4088 [==============================] - 705s 172ms/step - loss: 1.1194 - acc: 0.8991 - val_loss: 2.7223 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.76773\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088/4088 [==============================] - 705s 172ms/step - loss: 1.0685 - acc: 0.9101 - val_loss: 2.5971 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.76773 to 0.77541, saving model to highest_val_acc.h5\n",
      "Epoch 42/50\n",
      "4088/4088 [==============================] - 700s 171ms/step - loss: 1.0042 - acc: 0.9253 - val_loss: 2.5340 - val_acc: 0.7843\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.77541 to 0.78428, saving model to highest_val_acc.h5\n",
      "Epoch 43/50\n",
      "4088/4088 [==============================] - 746s 182ms/step - loss: 1.1345 - acc: 0.9015 - val_loss: 2.8727 - val_acc: 0.7308\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.78428\n",
      "Epoch 44/50\n",
      "4088/4088 [==============================] - 738s 181ms/step - loss: 1.1012 - acc: 0.9071 - val_loss: 2.6242 - val_acc: 0.7606\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.78428\n",
      "Epoch 45/50\n",
      "4088/4088 [==============================] - 730s 179ms/step - loss: 0.9801 - acc: 0.9291 - val_loss: 2.5758 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.78428\n",
      "Epoch 46/50\n",
      "4088/4088 [==============================] - 754s 184ms/step - loss: 0.9807 - acc: 0.9274 - val_loss: 2.9865 - val_acc: 0.7175\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.78428\n",
      "Epoch 47/50\n",
      "4088/4088 [==============================] - 703s 172ms/step - loss: 1.0573 - acc: 0.9130 - val_loss: 2.6410 - val_acc: 0.7657\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.78428\n",
      "Epoch 48/50\n",
      "4088/4088 [==============================] - 697s 170ms/step - loss: 0.9908 - acc: 0.9270 - val_loss: 2.3323 - val_acc: 0.7831\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.78428\n",
      "Epoch 49/50\n",
      "4088/4088 [==============================] - 715s 175ms/step - loss: 0.9281 - acc: 0.9381 - val_loss: 2.2836 - val_acc: 0.8191\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.78428 to 0.81915, saving model to highest_val_acc.h5\n",
      "Epoch 50/50\n",
      "4088/4088 [==============================] - 712s 174ms/step - loss: 0.9024 - acc: 0.9413 - val_loss: 2.3293 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.81915\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbda3e64f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
