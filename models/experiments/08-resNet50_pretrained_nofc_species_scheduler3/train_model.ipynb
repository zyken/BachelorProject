{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 3\n",
    "train_dir = \"../../../images/images_species/train/\"\n",
    "val_dir = \"../../../images/images_species/val/\"\n",
    "train_images = 12263\n",
    "val_images = 3381\n",
    "save_model_name = \"restnet50pretrained.h5\"\n",
    "save_plot_name = \"resnet50pretrained_trainplot.png\"\n",
    "model_name = 'resNet50pretrained_highest_val_acc.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/batch_size) + 1\n",
    "validation_steps = int(val_images/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/herri/.local/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/home/herri/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "### Model building ####\n",
    "\n",
    "base_model = ResNet50(\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=\"imagenet\")\n",
    "\n",
    "#add a new dense layer to the end of the network inplace of the old layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Dense(4096, activation='relu')(x)\n",
    "\n",
    "# add the outplut layer\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# create new model composed of pre-trained network and new final layers\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          409800      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,997,512\n",
      "Trainable params: 23,944,392\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='sgd',\n",
    "            metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 200 classes.\n",
      "Found 3381 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = model_name\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', mode='max', patience=10)\n",
    "\n",
    "def schedule_func(epoch, lr):\n",
    "    if lr < 0.0001:\n",
    "        return lr\n",
    "    elif epoch % 12 == 0 and epoch > 0:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr\n",
    "    \n",
    "scheduler = LearningRateScheduler(schedule_func, 1)\n",
    "\n",
    "callbacks = [checkpoint, early_stop, scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 419s 103ms/step - loss: 2.6188 - acc: 0.3673 - val_loss: 2.2165 - val_acc: 0.4639\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46395, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 403s 98ms/step - loss: 0.9535 - acc: 0.7162 - val_loss: 1.5989 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.46395 to 0.61525, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 409s 100ms/step - loss: 0.5390 - acc: 0.8355 - val_loss: 2.0180 - val_acc: 0.5842\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.61525\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 412s 101ms/step - loss: 0.3284 - acc: 0.8985 - val_loss: 1.2027 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61525 to 0.71513, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 412s 101ms/step - loss: 0.2023 - acc: 0.9407 - val_loss: 1.1809 - val_acc: 0.7219\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71513 to 0.72193, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 412s 101ms/step - loss: 0.1226 - acc: 0.9657 - val_loss: 1.0592 - val_acc: 0.7751\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72193 to 0.77512, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 412s 101ms/step - loss: 0.0721 - acc: 0.9814 - val_loss: 1.0371 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.77512 to 0.77985, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 412s 101ms/step - loss: 0.0395 - acc: 0.9923 - val_loss: 0.9890 - val_acc: 0.7905\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.77985 to 0.79048, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 412s 101ms/step - loss: 0.0300 - acc: 0.9949 - val_loss: 0.9948 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.79048 to 0.81147, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 415s 101ms/step - loss: 0.0254 - acc: 0.9952 - val_loss: 0.7704 - val_acc: 0.8499\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.81147 to 0.84988, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 420s 103ms/step - loss: 0.0191 - acc: 0.9964 - val_loss: 0.7977 - val_acc: 0.8413\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.84988\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
      "4088/4088 [==============================] - 420s 103ms/step - loss: 0.0160 - acc: 0.9974 - val_loss: 0.7803 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.84988 to 0.85136, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0009999999776482583.\n",
      "4088/4088 [==============================] - 420s 103ms/step - loss: 0.0078 - acc: 0.9991 - val_loss: 0.7367 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.85136 to 0.85875, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 420s 103ms/step - loss: 0.0060 - acc: 0.9997 - val_loss: 0.7243 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.85875 to 0.86702, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 420s 103ms/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.7025 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.86702\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 410s 100ms/step - loss: 0.0059 - acc: 0.9995 - val_loss: 0.7261 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.86702\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 0.7308 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.86702\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.7313 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.86702\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.7135 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.86702\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0043 - acc: 0.9998 - val_loss: 0.7262 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.86702\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0042 - acc: 0.9998 - val_loss: 0.7208 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.86702\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0039 - acc: 0.9997 - val_loss: 0.7271 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.86702\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0034 - acc: 0.9998 - val_loss: 0.7054 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.86702 to 0.86820, saving model to resNet50pretrained_highest_val_acc.h5\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0009999999310821295.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0031 - acc: 0.9999 - val_loss: 0.7193 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.86820\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 9.999999310821295e-05.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0030 - acc: 0.9999 - val_loss: 0.7243 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.86820\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0030 - acc: 0.9999 - val_loss: 0.7178 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.86820\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 408s 100ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.86820\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088/4088 [==============================] - 399s 98ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7349 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.86820\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 399s 98ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7182 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.86820\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 399s 98ms/step - loss: 0.0033 - acc: 0.9998 - val_loss: 0.7176 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.86820\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 399s 98ms/step - loss: 0.0034 - acc: 0.9998 - val_loss: 0.7295 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.86820\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 399s 98ms/step - loss: 0.0034 - acc: 0.9998 - val_loss: 0.7011 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.86820\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 9.99999901978299e-05.\n",
      "4088/4088 [==============================] - 399s 98ms/step - loss: 0.0032 - acc: 0.9998 - val_loss: 0.7123 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.86820\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=50,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    class_weight=the_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save\n",
    "model.save(save_model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
