{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(\"../..\") # relative path to module toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.applications import ResNet50\n",
    "#from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from toolkit import getLabelsFromDir, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "batch_size = 1\n",
    "val_dir = \"../../../images/images_species_shuffled/val/\"\n",
    "val_images = 3381\n",
    "datasetDir = \"images_species/\"\n",
    "saved_model = 'resNet50pretrained_highest_val_acc.h5'\n",
    "results_file = \"results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getLabelsFromDir(val_dir)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "validation_steps = int(val_images/batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3331 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(416, 416),\n",
    "                                                    shuffle=False,\n",
    "                                                    seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2497/3381 [=====================>........] - ETA: 24s"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_generator(val_generator, steps=validation_steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred3 = [y[-3:] for y in np.argsort(Y_pred, axis=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        if line == '':\n",
    "            continue\n",
    "        row_data = line.split(' ')\n",
    "        row_data = [data for data in row_data if data]\n",
    "        row['class'] = row_data[0] + \" \" + row_data[1]\n",
    "        row['precision'] = float(row_data[2])\n",
    "        row['recall'] = float(row_data[3])\n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['support'] = float(row_data[5])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    dataframe.to_csv('classification_report2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(val_generator.classes, y_pred, target_names=labels)\n",
    "classification_report_csv(report)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = val_generator.classes\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "plot_confusion_matrix(y_true, y_pred, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (val_generator.class_indices) # dict of label:index\n",
    "labels = dict((i,l) for l,i in labels.items()) # dict of index:label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pd.dataframe and save predictions to .csv\n",
    "#filenames=[datasetDir + name for name in val_generator.filenames]\n",
    "#y_pred_labels = [labels[y] for y in y_pred]\n",
    "#y_true_labels = [labels[y] for y in y_true]\n",
    "#y_pred3_labels = []\n",
    "#for i,top3 in enumerate(y_pred3):\n",
    "#    l = []\n",
    "#    for top in top3:\n",
    "#        l.append((labels[top], Y_pred[i][top]))\n",
    "#    y_pred3_labels.append(l)\n",
    "#\n",
    "#results=pd.DataFrame({\"Filename\":filenames,\n",
    "#                      \"Label\":y_true_labels,\n",
    "#                      \"Prediction1\":y_pred_labels,\n",
    "#                      \"Prediction3\":y_pred3_labels})\n",
    "#results.to_csv(results_file,index=True)\n",
    "\n",
    "# create pd.dataframe and save predictions to .csv\n",
    "filenames=[datasetDir + name for name in val_generator.filenames]\n",
    "y_pred_labels = [labels[y] for y in y_pred]\n",
    "y_true_labels = [labels[y] for y in y_true]\n",
    "y_pred3_labels_prob = []\n",
    "\n",
    "for i,top3 in enumerate(y_pred3):\n",
    "    l = []\n",
    "    for top in top3:\n",
    "        l.append(labels[top])\n",
    "        l.append(Y_pred[i][top])\n",
    "    y_pred3_labels_prob.append(l)\n",
    "y_pred3_labels_prob = np.array(y_pred3_labels_prob)\n",
    "\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Label\":y_true_labels,\n",
    "                      \"Prediction1\":y_pred_labels,\n",
    "                      \"Prediction3a\":y_pred3_labels_prob[:,0],\n",
    "                      \"Prediction3a_prob\":y_pred3_labels_prob[:,1],\n",
    "                      \"Prediction3b\":y_pred3_labels_prob[:,2],\n",
    "                      \"Prediction3b_prob\":y_pred3_labels_prob[:,3],\n",
    "                      \"Prediction3c\":y_pred3_labels_prob[:,4],\n",
    "                      \"Prediction3c_prob\":y_pred3_labels_prob[:,5],\n",
    "                     })\n",
    "results.to_csv(results_file,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
