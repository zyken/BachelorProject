{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D, Input, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import class_weight \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# own code\n",
    "import sys\n",
    "sys.path.append(\"..\") # relative path to module toolkit\n",
    "from toolkit import getLabelsFromDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "input_size = (224, 224, 3)\n",
    "num_classes = 44\n",
    "n = 50\n",
    "mini_batch_size = 24 #article takes 256\n",
    "epochs = 60 * 10 ** 4\n",
    "\n",
    "model_type = 'ResNet%dv2' % (n)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models_weighted')\n",
    "model_name = 'resnetOrig_%s_model.{epoch:03d}.h5' % model_type\n",
    "\n",
    "train_dir = \"../../images/images_genus/train/\"\n",
    "val_dir = \"../../images/images_genus/val/\"\n",
    "train_images = 12525\n",
    "val_images = 3454\n",
    "\n",
    "save_plot_name = \"resnetOrigBottleneck_weighted_trainplot.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(train_images/mini_batch_size) + 1\n",
    "validation_steps = int(val_images/mini_batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=64,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture as in \"Deep Residual Learning for Image Recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resnet_v23(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v2(input_shape, depth, num_classes):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    # Start model definition.\n",
    "    num_filters_in = 64\n",
    "    \n",
    "    if depth == 50:\n",
    "        residual_blockSize = [3, 4, 6, 3] # used for depth 34 and 50 layer depth models \n",
    "    else:\n",
    "        raise Exception(\"only depth 50 is available\")\n",
    "    first_layer = True\n",
    "    \n",
    "    #init first layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = resnet_layer(inputs,num_filters=num_filters_in, kernel_size=7, strides=2, activation=None)\n",
    "    x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Instantiate the stack of residual units\n",
    "    for blockSize in residual_blockSize:\n",
    "        for res_block in range(blockSize):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if first_layer:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0: \n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  \n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "        first_layer=False\n",
    "  \n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    y = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "    stage 2:  8x8,  512\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "\n",
    "    # Start model definition.\n",
    "    num_filters = 64\n",
    "    \n",
    "    if depth == 34 or depth == 50:\n",
    "        residual_blockSize = [3, 4, 6, 3] # used for depth 34 and 50 layer depth models \n",
    "    else:\n",
    "        raise Exception(\"only depth 34 and 50 are available\")\n",
    "    not_first_layer = False\n",
    "    \n",
    "    #init first layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=7,\n",
    "                  strides=2,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "    x = conv(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    # Instantiate the stack of residual units\n",
    "    for blockSize in residual_blockSize:\n",
    "        for res_block in range(blockSize):\n",
    "            strides = 1\n",
    "            if not_first_layer and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if not_first_layer and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                \n",
    "                # Equivalent to option B in paper, where only projection shortcuts are used for \n",
    "                # dimensionality(number of filters) increase.\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            elif not(not_first_layer):\n",
    "                not_first_layer = True\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    print(x.shape)\n",
    "    \n",
    "    y = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_v2(input_shape=input_size, depth=n, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 256)  16640       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 256)  1024        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 256)  1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 256)  65792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 512)  131584      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  131584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 256)  131328      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 256)  590080      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 512)  131584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 512)  2048        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 256)  131328      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 256)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 256)  590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 512)  131584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 512)  2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 256)  131328      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 256)  1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 256)  590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 256)  1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 512)  131584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 512)  2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 512)  262656      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 14, 14, 512)  2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 512)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 512)  2359808     activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 512)  2048        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 512)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 1024) 525312      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 525312      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 1024) 4096        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 512)  524800      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 512)  2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 512)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 512)  2359808     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 512)  2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 512)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 1024) 525312      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 1024) 4096        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 512)  524800      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 512)  2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 512)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 512)  2359808     activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 512)  2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 512)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 1024) 525312      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 1024) 4096        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 512)  524800      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 512)  2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 512)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 512)  2359808     activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 512)  2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 512)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 1024) 525312      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 1024) 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 512)  524800      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 512)  2048        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 512)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 512)  2359808     activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 512)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 1024) 525312      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 1024) 4096        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 512)  524800      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 512)  2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 512)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 512)  2359808     activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 512)  2048        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 512)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 1024) 525312      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 1024) 4096        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 1024)   1049600     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 1024)   4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 1024)   9438208     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 1024)   4096        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 2048)   2099200     add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           conv2d_47[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 2048)   8192        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 1024)   2098176     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 1024)   4096        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 1024)   9438208     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 1024)   4096        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 1024)   2098176     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 1024)   4096        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 1024)   9438208     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 1024)   4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 44)           90156       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 66,591,660\n",
      "Trainable params: 66,531,884\n",
      "Non-trainable params: 59,776\n",
      "__________________________________________________________________________________________________\n",
      "ResNet50v2\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.1,momentum=0.9, decay=0.0001),\n",
    "              #optimizer=SGD(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=0.1,\n",
    "                               cooldown=0,\n",
    "                               verbose=1,\n",
    "                               patience=0,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "early_stop = EarlyStopping(patience=2)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12263 images belonging to 44 classes.\n",
      "Found 3381 images belonging to 44 classes.\n"
     ]
    }
   ],
   "source": [
    "assert(getLabelsFromDir(train_dir) == getLabelsFromDir(val_dir))\n",
    "labels = getLabelsFromDir(train_dir)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "#no augmentation other than rescaling pixels\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=mini_batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=input_size[:2] )\n",
    "val_generator = val_datagen.flow_from_directory(val_dir,\n",
    "                                                    classes=labels,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=mini_batch_size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=input_size[:2] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600000\n",
      "522/522 [==============================] - 354s 677ms/step - loss: 10.5057 - acc: 0.2398 - val_loss: 9.0607 - val_acc: 0.2560\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.25601, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.001.h5\n",
      "Epoch 2/600000\n",
      "522/522 [==============================] - 343s 656ms/step - loss: 8.5063 - acc: 0.2532 - val_loss: 7.9765 - val_acc: 0.2525\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.25601\n",
      "Epoch 3/600000\n",
      "522/522 [==============================] - 343s 657ms/step - loss: 7.5328 - acc: 0.2530 - val_loss: 7.0995 - val_acc: 0.2609\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.25601 to 0.26093, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.003.h5\n",
      "Epoch 4/600000\n",
      "522/522 [==============================] - 343s 658ms/step - loss: 6.7371 - acc: 0.2472 - val_loss: 6.4978 - val_acc: 0.2520\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.26093\n",
      "Epoch 5/600000\n",
      "522/522 [==============================] - 344s 660ms/step - loss: 5.9494 - acc: 0.2662 - val_loss: 5.8109 - val_acc: 0.1523\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.26093\n",
      "Epoch 6/600000\n",
      "522/522 [==============================] - 345s 661ms/step - loss: 5.2216 - acc: 0.3222 - val_loss: 6.4784 - val_acc: 0.1419\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.26093\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 7/600000\n",
      "522/522 [==============================] - 346s 663ms/step - loss: 4.8203 - acc: 0.3532 - val_loss: 4.7701 - val_acc: 0.3522\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.26093 to 0.35216, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.007.h5\n",
      "Epoch 8/600000\n",
      "522/522 [==============================] - 347s 664ms/step - loss: 4.7190 - acc: 0.3632 - val_loss: 4.7398 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.35216\n",
      "Epoch 9/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.6445 - acc: 0.3765 - val_loss: 4.8297 - val_acc: 0.3183\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.35216\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 10/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.6010 - acc: 0.3734 - val_loss: 4.5731 - val_acc: 0.3710\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.35216 to 0.37098, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.010.h5\n",
      "Epoch 11/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.5746 - acc: 0.3825 - val_loss: 4.5345 - val_acc: 0.3779\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.37098 to 0.37793, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.011.h5\n",
      "Epoch 12/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.5619 - acc: 0.3868 - val_loss: 4.5344 - val_acc: 0.3823\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.37793 to 0.38228, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.012.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 13/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.5594 - acc: 0.3877 - val_loss: 4.5372 - val_acc: 0.3785\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.38228\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 14/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.5736 - acc: 0.3834 - val_loss: 4.5274 - val_acc: 0.3779\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.38228\n",
      "Epoch 15/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.5613 - acc: 0.3875 - val_loss: 4.5462 - val_acc: 0.3730\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.38228\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 16/600000\n",
      "522/522 [==============================] - 347s 665ms/step - loss: 4.5567 - acc: 0.3885 - val_loss: 4.5199 - val_acc: 0.3846\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.38228 to 0.38459, saving model to /home/herri/Documents/BachelorProject/models/resnetBottleneckOriginal/saved_models_weighted/resnetOrig_ResNet50v2_model.016.h5\n",
      "Epoch 17/600000\n",
      "522/522 [==============================] - 347s 664ms/step - loss: 4.5594 - acc: 0.3878 - val_loss: 4.5313 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.38459\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 5e-07.\n",
      "Epoch 18/600000\n",
      "522/522 [==============================] - 344s 659ms/step - loss: 4.5658 - acc: 0.3855 - val_loss: 4.5359 - val_acc: 0.3817\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.38459\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the batches generated by generator.\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=epochs,\n",
    "                    #verbose=1,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4VHW6wPHvm0kPSQgJLYUqPRBKCPZFEcWyWBHEioUrNvZudZv1enVX13Xddb1iYW2IYsUVLCiorFJC74ROCjWQSvrv/nFOwiQkYUKmhXk/zzPPzJz6zjCcN796xBiDUkop5YogXweglFKq7dCkoZRSymWaNJRSSrlMk4ZSSimXadJQSinlMk0aSimlXKZJQymllMs0aaiAJyKLROSIiIT5Ohal/J0mDRXQRKQHcB5ggPFePG+wt86llDtp0lCB7hZgCfAv4NbahSISISJ/EZHdIlIgIotFJMJed66I/CAiR0Vkr4jcZi9fJCJ3Oh3jNhFZ7PTeiMi9IpIFZNnL/mYfo1BEVojIeU7bO0TkdyKyXUSK7PUpIvKCiPzF+UOIyFwR+W9PfEFKOdOkoQLdLcDb9uMSEelsL38GGAGcDXQAfg3UiEh3YD7wd6AjMBRY3YLzXQWMAgba75fbx+gAzALmiEi4ve7nwA3AZUAMcDtQCrwO3CAiQQAikgBcZO+vlEdp0lABS0TOBboD7xljVgDbgcn2xfh2YLoxJscYU22M+cEYUw5MBhYYY94xxlQaYw4bY1qSNJ40xuQbY44BGGPeso9RZYz5CxAG9LO3vRP4gzFmi7GssbddBhQAY+ztJgGLjDH7W/mVKHVSmjRUILsV+NIYc8h+P8telgCEYyWRhlKaWO6qvc5vROSXIrLJrgI7CsTa5z/ZuV4HbrJf3wS82YqYlHKZNsapgGS3T1wPOERkn704DGgPdAXKgN7Amga77gUymjhsCRDp9L5LI9vUTSttt1/8GqvEsMEYUyMiRwBxOldvYH0jx3kLWC8iacAA4OMmYlLKrbSkoQLVVUA1VtvCUPsxAPgeq53jNeBZEUm0G6TPsrvkvg1cJCLXi0iwiMSLyFD7mKuBa0QkUkTOAO44SQzRQBVwEAgWkYew2i5qvQI8LiJ9xDJEROIBjDHZWO0hbwIf1FZ3KeVpmjRUoLoVmGmM2WOM2Vf7AP4B3Ag8CKzDujDnA38Cgowxe7Aapn9hL18NpNnH/CtQAezHqj56+yQxfAF8DmwFdmOVbpyrr54F3gO+BAqBV4EIp/WvA4PRqinlRaI3YVKqbRKR87Gqqbob/Y+svERLGkq1QSISAkwHXtGEobxJk4ZSbYyIDACOYjXYP+fjcFSA8WjSEJFxIrJFRLaJyIPNbHetPVo23WnZb+39tojIJZ6MU6m2xBizyRgTZYw52xhT6Ot4VGDxWJdbEXEALwBjgWxguYjMNcZsbLBdNFYxe6nTsoFYA5YGAYnAAhHpa4yp9lS8SimlTs6T4zQygG3GmB0AIjIbuBLY2GC7x7F6pvzKadmVwGx7BO5OEdlmH+/Hpk6WkJBgevTo4b7olVIqAKxYseKQMaajq9t7MmkkUb/7YDbWnDt1RGQ4kGKM+UxEftVg3yUN9k1qeAIRmQpMBejWrRuZmZluCl0ppQKDiOxuyfY+awi35/d5Fqu/+ykxxswwxqQbY9I7dnQ5USqllDpFnixp5GDNnVMr2V5WKxpIBRaJCFhTLswVkfEu7KuUUsoHPFnSWA70EZGeIhKK1bA9t3alMabAGJNgjOlhjOmBVR013hiTaW83SUTCRKQn0AdY5sFYlVJKucBjJQ1jTJWI3Ic1VYIDeM0Ys0FEHgMyjTFzm9l3g4i8h9VoXgXcqz2nlFLK906baUTS09ONNoQrpVTLiMgKY0z6ybe06IhwpZRSLtOkoZRSymV6EyallAKqqmsorazmWEU1JeVVlDo/V1RRWm4/V1RTUVVDWEgQYcEOwoKDCA+xnsOCgwgLcRBuP9cuq1tvP4c42u7f65o0lFInyC+poPBYJaUV1RyrtC6UpRXWBdV6XWW9rqxdVlV/fWU1xyqqqKo29OrYjkGJMaQmxTIoMYauseHY3ew9rqKqhh2HitmUV8imvCJ2Hy6hpPzEJFBSXkV5VY1XYgJwBAlhwUG0Cwumc0y4/QijS0w4nWOt913sZbERIV77vlyhSUOpAGaMIfvIMdbnFLAht5ANuQWszy3kYFG5S/uHOISIEAeRocFEhjqICHUQGeogNiKErjHhiEDWgWK+3ryf2j43cZEhpCbFMjAxhkGJsaQmxtAjPoqgoNZdGA8Vl7M5r8hOEIVs2lfEtgNFVFZbJw51BNE9PpLo8GDahQXTKTqMqNBgIsMc1nNoMFFhjrrniBAHUWHW56p7trcPCQqiorqG8soayquqKbOfy6vs58oayqtqKKt0WlZlbe+8rOBYJfsLy8k+UsqK3fkcKa084XOFBQfVJZFOdmLpEhtOJ6fE0jkmnPAQR6u+P1dp0lAqQFTXGHYcLGZ9bgEbcgrrkkRhWRVg/fXbp1M7zuuTwMCuMXSICrUTgZ0QQqyEEBkaXJccXK1mKa2oYlNeERtqz51XwGuLd9Zd0KNCHXVJZGBiDKmJsfTp3K7R41dW17DjYEm95LApr36i6xQdRv+uMZzf1/os/bvE0KtjlHuqhQpyIH8H4d3OIjwyBAhp/TFtZZXVHCwqZ19hGfsLy9hXUMaBonL2FVjv1+cUsGDTfsoq65eKBiXG8NkD57ktjuZo0lDqNFReVc3WfcV2ycEqRWzKK6y72IQFB9G/awxXpCWSmmhVG/XrEu2xv1YjQ4MZ0T2OEd3j6pZVVNWQdaDITmBWjO9l7qW0whqSFeoIom+XdqQmxpLSIbIuUWw7UExFtfU5QhzCGZ2i6xJd/y4xDOgaTXy7MPd/iOID8P2zkPkaVJdDdFcYdjMMvwXap5x8fxeEhzhI6RBJSofIJrcxxlBYVsV+p8TirVIG6DgNpU4LxhhW7T3K+yuyWbXnKFn7i6iqsf5vR4cFH68KSrKee3eMIrjhX93GQGEu5K2BQ1ugXRfo1B8S+kFo0xcxd6quMew6XML6nAI25lqlofW5BRwtraRjdBj9u0QzsGsMA7rG0L9rNL07Nl4acavSfPjheVj6ElSVw9DJ0Gs0rJkN2xaACJwxFtKnQJ+LIch7F3AAamrgWD5EJZzS7i0dp6FJQ6k2rKisko9X5/L2kt1s3ldEVKiD9B4d6jU8p8RFntheYAwc2Ql5a60kUfsoPdTIWQTiekCnAdCxv/XcaQDE94GQcI9/RmMMJRXVtAvzcsVIeREseRF++Lv1OvVaGP1bSDjj+DZHdsPKN2DVm1C8H2KSrJLHsJsh9oSJud2nIAd2LITtC63njgNgymendChNGkoFgHXZBby9dDdz1+RSWlHNoMQYbhzVnfFDE0+8uNZUw+Ft9ZND3looL7DWBwVbF52uaccfHftZF8EDm+DgZjiwEQ5shvztUGO1gSBB0KFX/UTScQDEnwHBod79Qtyp8hgsfwUW/xVKD0P/K+CC30HnQU3vU10JW+bDipmw/Rvru+k7DkZMgTPGtL70UVECu/5jHXvHQuvfBCCqE/S+EPqMhcHXndKhNWkodZoqKa9i7ppcZi3dw7qcAiJCHIxPS2TyqG4MSY61umVWVVgXFOcEsX89VJZaBwkOty5+zgmi00AIdrENoKrCSkAHN1lJ5MBG63z5O8DYjbNBwdCht1211RdC21nHd4SAI6zB61BwhFqvHSH2OufX9vrgcHB4uKRRVQErX4fvnoHifdbF+MI/QNKIlh0nf6d1nFVvQclBiE05XvqI6eraMWpqYN8aK0lsXwh7lkBNpfU9dD/biq33hda/XSu742rSUOo0szG3kFnLdvPxqlyKy6vo1zmaG8/sxlXDkogJD7Hq3Ld+Dps/sy4ytQkitB10GVI/QST09czFt7IMDmdZieTgJquEcmATHNkFuOEaIw7okgrJGZA8ElJGQlzPVl8wAaiugrWzYdGfoGAPdDsLLvwj9DindcetqoAtn0HmTNj5rfUZ+l1qlT56XwhBDdpiCrKtBLH9G9ixyGqnAOg8GHpfYO3T7Sy3Vwlq0lDKS9bsPcr/ztvE4ZIKesRH0j0+iu72c4/4SJLaR5zY2OyiYxXV/HttLrOW7WHVnqOEBgdxxZCu3DiqG8O7xSFHd8PmeVai2POD9Vd+dCL0v8z6S7TrUOui2vDC5G3VVVZPo+oK6yJaXW5V5VSVN/O6wt7e6XVpPuSuhJyVUFFsHTsywUogyenWc9JwCIt2PbaaGtj4ESx80kp4XYfCmD9C7zHuSUbODm+HFf+C1W9bVV7tu8HwW62Sws5vrURxaKu1bbvOx0sSvUZDu07ujaUBTRpKeVh+SQVPf7GZ2cv3ktAujGEp7dmTX8quwyX1+s87goTkuIi6JNKtQyQ94qPokRBJclxko90ks/YX8fbSPXy4MpvCsip6d4xi8qjuXDsskfaFm60ksfkzq8oJrItOv8ug/+WQOMz9Fzt/U1NtlWCylx9/1F5sJcj6PpJHHn/En3Fi4jTGan9Y+IT1PXYcABf+3mq78PT3V1UOmz61Esiu761lwRENqpwGePXfUZOGUh5SXWOYtWwPz3yxhZLyKqac04MHxvQhOtwa3GWM4UBRObsPWwlk9+ESdh8urXtfZA+iA+ua0DUmvK50ktg+gsVZh1i2K58Qh3BpalduHNmVjKDNyOZ5sGUeFOy1LowpZ1pJov9lVkN0oCvNt0og2cshexlkrzjeyB/e3i6JZFjPxsCiJyEn0/ruRv8OUq/xfjdZgEPbrLaTpHSv9EJriiYNpTxgxe4jPDx3PetzCjmrVzyPXTmIPp1drwoxxnC0tJJdh0usUsmhUiup5FvPh4qtKq6bhydwfdwWond9abVTlBVYjZ+9L7QSRd9xp9wfP2DU1FilD+fSyIFN1LWtxCTDT35tjbdwuG80d1ulSUMpNzpUXM6f5m9mzopsusSE84crBnD54K5un0CufMO/CV39BrJjkVW/H9HBShD9L7caQUOj3Hq+gFNWaLWJ1HahdbW3WABoadLQaUSUakRVdQ1vLdnNX77aSlllNXf/pDf3X3gGUZ4YYHZ0L2Hv32wNDBt5p1XtlHKm57uYBpLwGKtRWbWa/iqVamDZznwe+mQ9m/cVcV6fBB4ZP4jeHdt57oSZr1rPU+ZZvWqU8mOaNJSyHSgs48n5m/loVQ6JseG8eONwxqV28ey9DCrLYMXrVg8oTRiqDdCkoQJeZXUNr/+wi+cWZFFRVcN9F5zBPRf0JjLUC/891n9gDeLKmOr5cynlBpo0VED7cfthHp67nq37ixndryMP/3QQPRO81OhsDCx7yZq7qef53jmnUq2kSUMFpLyCY/zvvM18uiaX5LgIZtw8grEDO3v3tprZmdbcUJf/5fQflKdOG5o0VEDZkFvAq9/v5NO1uYgI08f0Ydro3l69iU2dZS9BWAwMmeT9cyt1ijRpqNNeTY3h260Hefn7Hfyw/TCRoQ5uHNWdO87t2ewd0jyqaD9s+NjqYhvmwZ5ZSrmZJg112iqrrObDlTm8ungH2w+W0CUmnAcv7c8NGd2IjfDxSOAV/7Kmuh55p2/jUKqFNGmo087BonLeXLKbt5bsJr+kgkGJMTw3cSiXD+nq+VuDuqK60rrP9BkX1b8LnFJtgCYNddrYur+IV7/fyUerc6ioquGiAZ2449xenNmrg3cbuE9m01xrorqM530diVItpklDtWnGGBZvO8Qr3+/k260HCQ8JYsKIZG4/t6dnR3G3xrKXrXtun3GRryNRqsU0aag2qbyqmrmrc3l18U427ysioV0Yv7y4L5NHdadDlB/fnzpvLez5ES5+wjfTcSvVSpo0VJtScKySN37Yxes/7uZQcTn9u0Tz9HVDGD80kbDgNnARXjYDQiJh2I2+jkSpU+LRpCEi44C/AQ7gFWPMUw3W3w3cC1QDxcBUY8xGEekBbAK22JsuMcbc7clYlf+rqKrhgZc+gwMbObPnCCZOzODcMxL8q72iOaX5sG4OpE2CiDhfR6PUKfFY0hARB/ACMBbIBpaLyFxjzEanzWYZY/7P3n488Cwwzl633Rgz1FPxqbbnL19u4brDL/LT0CWQA/w7xbrFadJwSBwOiUMhPNbXYTZt1ZtQVabzTKk2zZMljQxgmzFmB4CIzAauBOqShjGm0Gn7KOpuraVUfYuzDvHSdzv4vkMBxAyBIddbt/jMXWn1RqqV0NdKILWJpMtgn95Ks05NNSx/BbqfC50H+ToapU6ZJ5NGErDX6X02MKrhRiJyL/BzIBS40GlVTxFZBRQCfzDGfN/IvlOBqQDduum00qerw8Xl/Py91fTuGEUyR6HLhXD2/cc3KM23kkfOKshZATsWwtrZ1rqgYOg08HgSSRoOHQd4/wZHW7+Ao3tg7OPePa9SbubzhnBjzAvACyIyGfgDcCuQB3QzxhwWkRHAxyIyqEHJBGPMDGAGWLd79XLoyguMMfzmg7UcLa3kX7cOR17dD9Fd628U2cHqvlrbhdUYKMy1E4ldGtnwkTUKGyA4ArqmQfrtkDbROx9k2UvWnfn6X+Gd8ynlIZ5MGjlAitP7ZHtZU2YDLwIYY8qBcvv1ChHZDvQF9CbgAeatJbtZsOkAD10xkIExZWBqIKZr8zuJQGyS9RjwU2tZTQ0c2Xk8iexYBB/fbR3L09OSH9xine/CP+gtXFWb58k5FZYDfUSkp4iEApOAuc4biEgfp7eXA1n28o52Qzoi0gvoA+zwYKzKD23ZV8T/fLaJ0f06MuWcHlCYZ62ISWr5wYKCIL43DJkA456EO76E+DPg/TugaJ9b4z7B8lfAEQrDb/PseZTyAo8lDWNMFXAf8AVW99n3jDEbROQxu6cUwH0iskFEVmO1a9xqLz8fWGsvfx+42xiT76lYlf8pq6zmgXdWER0ezNPXpVndaotyrZUNq6dORVg0XP8GVBTD+7dDdVXrj9mYskJYPQsGXQPtOnrmHEp5kUfLysaYecC8Bssecno9vYn9PgA+8GRsyr89OW8TW/YX8a8pI+kYHWYtrCtpJLrnJJ0GwBV/hY/+C755HMY+6p7jOlsz20pMo7SbrTo9+MGUn0rV9/Wm/bz+425uP6cno/t1Or6iMAeCQiAywX0nS5sEI26D/zwHW+a777hgtaMsmwFJI6yHUqcBTRrKrxwoLONX769lQNcYfnNpv/ori/IguovVPuFO4/4EXYZYJY4ju9x33J2L4HAWZPyX+46plI9p0lB+o6bG8Is5ayitqOLvNww9cS6pwlz3VU05Cwm32jcM8N6tUFXunuMunQFRHWHQVe45nlJ+QJOG8huvLt7J91mHeOiKQZzRKfrEDYry3NMI3pgOPeHqFyFvNXz+29Yf78gu2Pq5VfUVHNb64ynlJzRpKL+wPqeAP3+xmUsGdeaGjJQTNzDGagj3REmjVv/LrZHmma/C2jmtO9byV0CCYMQU98SmlJ/QpKF8rqS8igfeWUV8VBhPXTOk8VlrywqgssRzJY1aYx6GbmfBp9OtQXmnoqIUVr4JA66wBhgqdRrRpKF87rFPN7LzcAnPTkwjrqkbKBW5ubttUxwhcN1rEBIB790CFSUtP8a6OVB2VBvA1WlJk4byqc/W5vFu5l7uGd2bs3s305W20I0D+04mJhGue9UqaXz6M6tqzFXGWLdz7TQIup/tuRiV8hFNGspnco4e47cfriUtpT0/u6hv8xt7q6RRq9douOB3sO49WDHT9f32/Aj711mD+drKzaGUagFNGsonqmsM/z17NdU1hucnDSXEcZKfYu1ocG+UNGqd90voPQbm/wZyV7m2z7IZ1o2gBk/wbGxK+YgmDeUT/1y4jWW78nn8qlS6x0edfIfCHIjo4N0bKgUFwTUvW2Mt3rsVjh1pfvvCXNg4F4bdDKEufCal2iBNGsrrVuw+wnNfZ3Hl0ESuHuZi76IiD3e3bUpUPEx43UpaH9/TfPtG5kxr6vaRd3ovPqW8TJOG8qrCskqmz15FYvtwHr8qtfHutY3umOvdqilnKSPh4v+BLfPgh+cb36aq3Gr76HuJNVBQqdOUJg3lNcYY/vjxevIKynhu4jBiwkNc39lXJY1ao+6GgVfCgkdh9w8nrt/4CZQchIy7vB+bUl6kSUN5zUercvhkdS4/G9OHEd3jXN+xqsK6IPsyaYjA+H9AXA+YMwWKD9Rfv2yGdVOnXhc2urtSpwtNGsordh8u4Y8fryejRwfuueCMlu1c5IOeU40Jj7EmNiw7Ch/cATXV1vKclZC9HEbe5f4ZeJXyM/oLV17x9BdbCBLhr5OG4ghq4fgFb4/RaE6XVLj8L7DzO1j0pLVs2csQ2g6GTvZtbEp5gd7lXnnc4eJyvtiwj5vP7EFS+4iWH8Cbo8FdMewmaxDfd09bVVLrP4DhN1slEaVOc5o0lMd9sDKbymrD5FGNzF7rCn8qadS67BnIXW3duAkgQ2/nqgKDVk8pjzLG8M6yvWT06ND4PTJcUZgLweEQ0YLGc08LibDaN0KjodcF0LHfyfdR6jSgJQ3lUUt25LPzUAkPjGlh47ez2jEa/jaXU3xvuG+Z1Z6hVIDQpKE8atayPcRGhHBpaivaI3w9RqM5/hqXUh6i1VPKYw4Xl/PF+n1cMzyJ8BDHyXdoii9Hgyul6tGkoTzmw5U5VFTXcENGt1M/iDFQtE//olfKT2jSUB5hNYDvIb17HH07n2IDOEBpPlSXa9JQyk9o0lAesXRnPjsOlTB5VCtKGWDNLgtaPaWUn9CkoTxi1tI9xIQHc9ngVl7s/XGMhlIBTJOGcrv8kgo+X7+Pa4Ynt64BHPxvNLhSAU6ThnK7D1dmt74BvFZRHiAQ3aX1x1JKtZomDeVWxhhmLdvDiO5x9OvSigbwWoW50K4TOFpw7w2llMdo0lButWxnPjsOlrinlAFWSUOrppTyGx5NGiIyTkS2iMg2EXmwkfV3i8g6EVktIotFZKDTut/a+20RkUs8Gadyn1nLrAbwK4a46UJfmKuN4Er5EY8lDRFxAC8AlwIDgRuck4JtljFmsDFmKPBn4Fl734HAJGAQMA74p3085ceOlFQwf52bGsBr6WhwpfyKJ0saGcA2Y8wOY0wFMBu40nkDY0yh09sowNivrwRmG2PKjTE7gW328ZQf+8BuAJ+UcYpToDdUecy6S56WNJTyG56csDAJ2Ov0PhsY1XAjEbkX+DkQCtTeYDkJWNJg36RG9p0KTAXo1s1NdejqlNSOAB/erT39u7jpZkS13W01aSjlN3zeEG6MecEY0xv4DfCHFu47wxiTboxJ79ixo2cCVC5ZvusI293ZAA7+c29wpVQdTyaNHMC5niLZXtaU2cBVp7iv8rFZS3cTHR7MFUPcWCrQkoZSfseTSWM50EdEeopIKFbD9lznDUSkj9Pby4Es+/VcYJKIhIlIT6APsMyDsapWOFJSwbz1+7hmWBIRoW7sr6CjwZXyOx5r0zDGVInIfcAXgAN4zRizQUQeAzKNMXOB+0TkIqASOALcau+7QUTeAzYCVcC9xphqT8WqWufDVTlUVNVwQ2snJ2yoKM+6nWq4m9pIlFKt5tE79xlj5gHzGix7yOn19Gb2fQJ4wnPRKXeobQAf5s4G8FqFuRCjpQyl/InPG8JV25a5+wjbDhS7twG8lo4GV8rvaNJQrTJr6R6iw9w4AtyZjgZXyu+4lDRE5EMRuVxENMmoOkdLK/hsXR5XDUsiMtTNNZ011dZtXrWkoZRfcTUJ/BOYDGSJyFMi0s+DMak24sOVdgO4J6qmSg6CqdaShlJ+xqWkYYxZYIy5ERgO7AIWiMgPIjJFRHTO6gBU2wA+NKU9AxM90LtJx2go5Zdcrm4SkXjgNuBOYBXwN6wk8pVHIlN+bcXuI2QdKGayJ0oZoKPBlfJTLlVEi8hHQD/gTeCnxhj7fzTvikimp4JT/mvW0j20CwvmijQPXdS1pKGUX3K19fJ5Y8zCxlYYY9LdGI9qA46WVvDvdXlcn57s/gbwWoW5IA6I0jnFlPInrlZPDRSR9rVvRCRORO7xUEzKz320yoMN4LVqx2gE6W1UlPInriaNu4wxR2vfGGOOAHd5JiTlz2obwNNS2jMoMdZzJ9LR4Er5JVeThkNEpPaNfRe9UM+EpPzZyj1H2Lq/mMnuutFSU3Q0uFJ+ydWk8TlWo/cYERkDvGMvUwHm7doGcHdOgd4YHQ2ulF9ytRXzN8B/AdPs918Br3gkIuW3Ckor+WxtHteNSCYqzINzXZYVQkWxljSU8kMu/c83xtQAL9oPFaA+WpVNuacbwOH4GI2YE+7wq5TyMVfHafQBngQGAuG1y40xvTwUl/IzVgP4XoYkx5Ka5MEGcHAao6ElDaX8jattGjOxShlVwAXAG8BbngpK+Z+Ve46yZX+R50aAO9PR4Er5LVeTRoQx5mtAjDG7jTGPYN2eVQWId5btISrUwU/TvNA4XWjfDl4bwpXyO662Zpbb06Jn2bdwzQHaeS4s5U8KjlXy77W5XDPcww3gtQrzILw9hER4/lxKqRZxtaQxHYgEHgBGADdh389bnf4+XpVDWWWNd6qmwKqe0kZwpfzSSf9stAfyTTTG/BIoBqZ4PCrlN2pHgA9O8kIDeC0dDa6U3zppScMYUw2c64VYlB/K3H2EzfuKPN/N1pmOBlfKb7laQb1KROYCc4CS2oXGmA89EpXyC8t35TP1jUzio0IZP9RLjdLVlVB8QBvBlfJTriaNcOAwcKHTMgNo0jhNfbQqm9+8v47kuAhevW0k7bzRAA7WfcExWtJQyk+5OiJc2zEChDGGvy7I4vmvszizVwf+76YRtI/04tyUOhpcKb/m6ojwmVgli3qMMbe7PaJAV10Jh7dBQl+v30uirLKaX7+/lrlrcrluRDL/e/VgQoNdviOwe+hocKX8mqt1Dv92eh0OXA3kuj+cALZ/A6yeBWvfhZKDENsNht8Cw27yygX0cHE5U99cwYrdR/j1uH5M+0lvnGbD95660eDapqGUP3K1euoD5/ci8g6w2CMRBZLSfFj3Pqx+G/JWQ1AI9BsHPX8Cmz4D90EwAAAgAElEQVSFhf8Di56EfpfCiCnQ+0IIcv9f/ln7i7j99eUcKCznnzcO57LBPvwrvzAHHGEQ2cF3MSilmnSqrZt9gE7uDCRgVFfB9q9h1VuwZT7UVEKXITDuTzB4AkTFW9tl3AWHt8PK12HV27D539C+Gwy/FYbdDNGd3RLO4qxDTHt7BWHBDt79r7MYmtL+5Dt5UmEeRHcBX5RylFIn5WqbRhH12zT2Yd1jo+0zBjbNhfg+0KEXhISffJ9TcWCTVaJY8y6UHIDIBMiYCkNvgC6DG98nvjeMfQwu+L2VNDJnwjeP26WPyyB9CvQcfcqlj1lL9/DHT9bTp1M7Xrk1neS4yFP/fO5SlKfdbZXyY65WT0V7OhCfKd4P791ivxGI6241Qif0hYQ+1nN8H4hKaPlfv6X5sP4Dq60idyUEBUOfS2DYjXDGWAh2sVdScBikXms9Dm2DFTOtY26aC3E9YMRtMPRGaOda4a+6xvDU/E28/P1ORvfryN9vGEZ0eEjLPpunFOZC0nBfR6GUaoIYc0KnqBM3Erka+MYYU2C/bw+MNsZ87OH4XJaenm4yMzNbvmN1pVUKOLQVDmVZz4ezrItz1bHj24W3PzGZJPSxLtoO64JbXlVNdVUlwTsX4Vg3m6AtnyHVFdA51bqoD54A7Tq65wNXllntHitmwu7/WO0h/S+3Sh89zm+y9FFaUcX02av5auN+bj2rO3+8YiDBDi/3kGqKMfBEFxh5J1zyhK+jUSogiMgKY0y6y9u7mDRWG2OGNli2yhgz7CT7jQP+BjiAV4wxTzVY/3PgTqz7dBwEbjfG7LbXVQPr7E33GGPGN3euU04aTampgcLs+snkUJb1KN53fLugYGriepJVk8iqQ8FcELSCznKUfNOOT6rPYU71T9hEDxwiBAWJ9SxYr4OEILEejiBwiCAihIcEMaxbHGf1iufsM+LpGnuS2V4PboEV/7JKH2VHrWq22tJHVELdZvsKyrjj9eVsyivkoSsGcts5Pd33fblDaT78uSdc8r9w1r2+jkapgOCppLHWGDOkwbJ1xpgmKuPrJjrcCowFsoHlwA3GmI1O21wALDXGlIrINKzSy0R7XbExxuXp192eNJpTVgCHtmEObWHbxlXkZK0hsTqbbsH57IsbyaYuP2VXh/OoJJjqGkONMfYzda9rl1vvoabGUG2/LzxWRebufI6WVgLQMyGKs3rHc3bveM7sFU9Cu7DG46osg42fWKWPPT9apaP7V0BUAutzCrjj9eUUl1Xxj8nDuaC/H/Zj2Lce/u8cuG4mpF7j62iUCggtTRqu9p7KFJFngRfs9/cCK06yTwawzRizww5sNnAlUJc0jDELnbZfgjXluv8Lj2VbaD8ezqzkP9tiGZQ4nseuTCW8exw9gB5uOEVNjWHTvkJ+3H6YH7cfZu7qXGYt3QNA/y7RdhJJIKNnB2Ij7PaIkHBIm2g9tn4JsybA7v+wgDN5YPYq2keE8P60sxnQNcYNEXpA3WhwbQhXyl+5mjTuB/4IvIvVi+orrMTRnCRgr9P7bGBUM9vfAcx3eh8uIplYVVdPNdZ+IiJTgakA3bp5ZxbWkvIqnv8mi9cW7yQixMHjVw5i8qjuOILc20U0KEgYlBjLoMRY7jyvF1XVNazLKeAHO4m8s2wPM/+ziyCBwUmxnGknkZE94ogMDYZeozGOMNYt+Yq7soIZkhTLy7ek0ynGQ73D3KFuNLgmDaX8lau9p0qABz0VhIjcBKQDP3Fa3N0YkyMivYBv7Oqw7Q3imgHMAKt6ylPx2edi3rp9PP7vjewrLOP69GR+Pa5/01VFbhbssNo5hnWL494LzqC8qprVe47WJZHXFu/kpW93EOIQhqa056zeCVwd1pfKXUsYN2gKz14/lIhQ705L0mK1JY12XXwbh1KqSa6O0/gKmGCMOWq/jwNmG2MuaWa3HCDF6X2yvazhsS8Cfg/8xBhTXrvcGJNjP+8QkUXAMGB7w/29YduBYh6Zu4HF2w4xsGsML9w4nBHd43wRSp2wYAejesUzqlc8/z3W6hWVueuIlUR2HOYf32QR5ejGHSFf8sL1gwjy94QB1mjwqI6ud0VWSnmdq9VTCbUJA8AYc0RETtaSuhzoIyI9sZLFJGCy8wYiMgx4CRhnjDngtDwOKDXGlItIAnAO8GcXY3WbkvIq/v7NNl5dvIOIEAePXTmIGz1QFeUOkaHBnN+3I+f3tbr0FpZVUrbmGMHzP4P96yBlpI8jdEGh3nxJKX/natKoEZFuxpg9ACLSg0ZmvXVmjKkSkfuAL7C63L5mjNkgIo8BmcaYucDTQDtgjj05Xm3X2gHASyJSg3V3waece115Wm1V1P98tpG8gjImjEjmN5d6ryrKHWLCQ4gZeJ7VSrR3adtIGkV5EJvs6yiUUs1wNWn8HlgsIt8CApyH3QDdHGPMPGBeg2UPOb2+qIn9fgCa7M7rSQ2rov4x2fdVUacsurM1X1X2Ml9H4prCXEjJ8HUUSqlmuNoQ/rmIpGMlilXAx8Cx5vdqW5yrosL9vCqqRVJGwa7F1mhrf54EsLIMjuXrlOhK+TlXG8LvBKZjNWavBs4EfqT+7V/bJGMM89dbvaLaalVUs5IzYN0cKMiG9ikn395XivTmS0q1Ba5OOjQdGAnsNsZcgNWT6Wjzu7QNOw+VcN+slcRFhvLBtLN4ekLa6ZMw4Hh1j79XURXW3nxJk4ZS/szVNo0yY0yZWHMjhRljNotIP49G5iW9OrZj1l1nkt49zn8m7nOnzqkQEgl7l1mz5PorHQ2uVJvgatLItme2/Rj4SkSOALs9F5Z3ndkr3tcheI4jGBKHW0nDn+locKXaBFcbwq+2Xz4iIguBWOBzj0Wl3CslA354HiqPQchJZsz1laI8CImCMD+dF0spBZzC7V6NMd96IhDlQSkZUFMFuaug+9m+jqZxhTlWI7g/9/BSSrncEK7asmS7Mdyfq6h0NLhSbYImjUAQFQ8devt30tB7gyvVJmjSCBQpGVa3WxduuuV1NTWaNJRqIzRpBIqUDCg5CEd2+jqSE5UestpcdDS4Un5Pk0agqGvXWO7bOBpTaM+Yr6PBlfJ7mjQCRacBEBrtnyPD60aDa0lDKX+nSSNQBDkgeYQ1Tbq/0XmnlGozNGkEkuQM2L8Byot9HUl9hXkgDmjX2deRKKVOQpNGIEkZBaYGclb4OpL6ivKshBHUBm5Jq1SA06QRSJJHWM/+1q5ROxpcKeX3NGkEkog46Njf/3pQ6WhwpdoMTRqBJnmk/w3y04F9SrUZmjQCTUoGHDsCh7f5OhJLeTGUF2rSUKqN0KQRaFJGWc/+0vW2SMdoKNWWaNIINPF9IDzWfyYvLNQxGkq1JZo0Ak1QkDVeI9tPGsNrk4aWNJRqEzRpBKKUDDiwCcoKfB2JjgZXqo3RpBGIkkcCBrIzfR2J1d02PBZCo3wdiVLKBZo0AlHSCJAg/2jXKMrTqiml2hBNGoEoPAY6DfSPkeGFuVo1pVQbokkjUKVkWNVTNTW+jaMwV0saSrUhmjQCVXKGNaju4GbfxVBdBSUHtKShVBuiSSNQpdh38vNlFVXxfmvWXR0NrlSboUkjUHXoBZHxvm0M19HgSrU5Hk0aIjJORLaIyDYRebCR9T8XkY0islZEvhaR7k7rbhWRLPtxqyfjDEgiVhWVL5OGjgZXqs3xWNIQEQfwAnApMBC4QUQGNthsFZBujBkCvA/82d63A/AwMArIAB4WkThPxRqwUjLgcBaU5vvm/DoaXKk2x5MljQxgmzFmhzGmApgNXOm8gTFmoTGm1H67BEi2X18CfGWMyTfGHAG+AsZ5MNbAVNeu4aMpRYpyISjEqiZTSrUJnkwaScBep/fZ9rKm3AHMb8m+IjJVRDJFJPPgwYOtDDcAJQ6z7s3tqyqqwjyraipIm9aUaiv84n+riNwEpANPt2Q/Y8wMY0y6MSa9Y8eOngnudBYaBV0G+26adB0NrlSb48mkkQOkOL1PtpfVIyIXAb8Hxhtjyluyr3KDlAzIWWmNmfA2HQ2uVJvjyaSxHOgjIj1FJBSYBMx13kBEhgEvYSWMA06rvgAuFpE4uwH8YnuZcreUUVBZAgc2eve8xuhocKXaII8lDWNMFXAf1sV+E/CeMWaDiDwmIuPtzZ4G2gFzRGS1iMy1980HHsdKPMuBx+xlyt2SR1rP3q6iKjsKVce0pKFUGxPsyYMbY+YB8xose8jp9UXN7Psa8JrnolMAtO8G7TpbPagy7vLeeQvtgX06GlypNsUvGsKVD4lY7RreLmkU6RgNpdoiTRrKGhl+ZBcUe7Hbcl1JQ6unlGpLNGkoqzEcvDt5Yd1ocE0aSrUlmjQUdE2zRmZ7s4qqKNcaCR4c5r1zKqVaTZOGgpBwK3Hs9eJ0IoV52giuVBukSUNZUkZB7kqoqvDO+Yp0jIZSbZEmDWVJGQlVZbB/nXfOVzvvlFKqTdGkoSzJ9oy33qiiqiqH0kNa0lCqDdKkoSyxSRCT7J3G8CLtbqtUW6VJQx2XMtI799bQ0eBKtVmaNNRxKaOgYO/xMRSeoqPBlWqzNGmo4+raNTw8yE9HgyvVZmnSUMd1GQzB4Z6voirMheAICG/v2fMopdzOo7PcqjYmONS6BaynG8OL7JsviXj2PAGusrKS7OxsysrKfB2K8gPh4eEkJycTEhLSquNo0lD1JY+Epf8HlWXWSHFPKNTbvHpDdnY20dHR9OjRA9EEHdCMMRw+fJjs7Gx69uzZqmNp9ZSqL2UUVFdA3hrPnaMoV3tOeUFZWRnx8fGaMBQiQnx8vFtKnZo0VH0pdmO4p2a8ramBon3aCO4lmjBULXf9FjRpqPradYL23T3Xg6r0sFWS0eoppdokTRrqRCmjrKRhjPuPXTtGQ0sap72jR4/yz3/+85T2veyyyzh69Giz2zz00EMsWLDglI6vTp0mDXWilAwo3mcN9HO32jEaWtI47TWXNKqqqprdd968ebRv33yX7Mcee4yLLrrolOPzhZN97rZAe0+pE6U4DfJr3829x64raWjS8KZHP93AxtxCtx5zYGIMD/90UJPrH3zwQbZv387QoUMZO3Ysl19+OX/84x+Ji4tj8+bNbN26lauuuoq9e/dSVlbG9OnTmTp1KgA9evQgMzOT4uJiLr30Us4991x++OEHkpKS+OSTT4iIiOC2227jiiuu4LrrrqNHjx7ceuutfPrpp1RWVjJnzhz69+/PwYMHmTx5Mrm5uZx11ll89dVXrFixgoSEhHqxTps2jeXLl3Ps2DGuu+46Hn30UQCWL1/O9OnTKSkpISwsjK+//prIyEh+85vf8PnnnxMUFMRdd93F/fffXxdzQkICmZmZ/PKXv2TRokU88sgjbN++nR07dtCtWzeefPJJbr75ZkpKSgD4xz/+wdlnnw3An/70J9566y2CgoK49NJLueuuu5gwYQIrV64EICsri4kTJ9a99wVNGupEnQZBSJSVNAZf595jF+aBBEG7zu49rvI7Tz31FOvXr2f16tUALFq0iJUrV7J+/fq6bp+vvfYaHTp04NixY4wcOZJrr72W+Pj4esfJysrinXfe4eWXX+b666/ngw8+4KabbjrhfAkJCaxcuZJ//vOfPPPMM7zyyis8+uijXHjhhfz2t7/l888/59VXX2001ieeeIIOHTpQXV3NmDFjWLt2Lf3792fixIm8++67jBw5ksLCQiIiIpgxYwa7du1i9erVBAcHk5+ff9LvYuPGjSxevJiIiAhKS0v56quvCA8PJysrixtuuIHMzEzmz5/PJ598wtKlS4mMjCQ/P58OHToQGxvL6tWrGTp0KDNnzmTKlCkt/adwK00a6kSOYEga7pkeVIW5ENXJOofymuZKBN6UkZFRb5zA888/z0cffQTA3r17ycrKOiFp9OzZk6FDhwIwYsQIdu3a1eixr7nmmrptPvzwQwAWL15cd/xx48YRFxfX6L7vvfceM2bMoKqqiry8PDZu3IiI0LVrV0aOHAlATEwMAAsWLODuu+8mONj6DXfo0OGkn3v8+PFEREQA1qDL++67j9WrV+NwONi6dWvdcadMmUJkZGS94955553MnDmTZ599lnfffZdlyzw8zc9J6P9c1biUDPjP36CiFEIj3Xfc2tHgKiBFRUXVvV60aBELFizgxx9/JDIyktGjRzc6jiAs7Ph95B0OB8eOHWv02LXbORyOFrUd7Ny5k2eeeYbly5cTFxfHbbfddkrjGYKDg6mpqQE4YX/nz/3Xv/6Vzp07s2bNGmpqaggPb34Q7bXXXltXYhoxYsQJSdXbtCFcNS45A2qqIHeVe4+ro8EDRnR0NEVFRU2uLygoIC4ujsjISDZv3sySJUvcHsM555zDe++9B8CXX37JkSNHTtimsLCQqKgoYmNj2b9/P/PnzwegX79+5OXlsXy5NRdbUVERVVVVjB07lpdeeqkuMdVWT/Xo0YMVK1YA8MEHHzQZU0FBAV27diUoKIg333yT6upqAMaOHcvMmTMpLS2td9zw8HAuueQSpk2b5vOqKdCkoZqSbBXJ3T4PlY4GDxjx8fGcc845pKam8qtf/eqE9ePGjaOqqooBAwbw4IMPcuaZZ7o9hocffpgvv/yS1NRU5syZQ5cuXYiOjq63TVpaGsOGDaN///5MnjyZc845B4DQ0FDeffdd7r//ftLS0hg7dixlZWXceeeddOvWjSFDhpCWlsasWbPqzjV9+nTS09NxOBxNxnTPPffw+uuvk5aWxubNm+tKIePGjWP8+PGkp6czdOhQnnnmmbp9brzxRoKCgrj44ovd/RW1mBhP9MX3gfT0dJOZmenrME4vfx8BCX3hhnfcc7yKEvjfRBjzEJz3C/ccUzVp06ZNDBgwwNdh+FR5eTkOh4Pg4GB+/PFHpk2bVtcw35Y888wzFBQU8Pjjj7fqOI39JkRkhTEm3dVjaJuGalpyBmR9aQ3yc8cUBDpGQ3nZnj17uP7666mpqSE0NJSXX37Z1yG12NVXX8327dv55ptvfB0KoElDNSclA9bMgvwdEN+79cfT0eDKy/r06cOqVW5ul/Oy2t5f/kLbNFTT6iYvdNNNmbSkoVSbp0lDNa1jfwiLcV9juJY0lGrzPJo0RGSciGwRkW0i8mAj688XkZUiUiUi1zVYVy0iq+3HXE/GqZoQ5ICkEbDXjSWNsBgIiz75tkopv+SxpCEiDuAF4FJgIHCDiAxssNke4DZgViOHOGaMGWo/xnsqTnUSPc6B/evg7eth94+tO1ZhDkRrKUOptsyTJY0MYJsxZocxpgKYDVzpvIExZpcxZi1Q48E4VGucdR9c8HvIyYSZ4+DVi2HLfOtmSi1VlKdVU6pZ7dq1AyA3N5frrmt83rPRo0dzsu71zz33XN0gOXBtqnXlGk8mjSTAeW7tbHuZq8JFJFNElojIVY1tICJT7W0yDx482JpYVVNCIuAnv4afrYdLn7aqmN6ZBC+eBavfgepK14+lo8GVixITE3n//fdPef+GScOVqdb9iTGmbkoSf+PPDeHd7QEnk4HnROSEPp/GmBnGmHRjTHrHjh29H2EgCY2EUVPhgZVwzcsgDvj4bvjbUFjyojVwrzk11VC8X0eD+8r8B2Hm5e59zD+hmbKeBx98kBdeeKHu/SOPPMIzzzxDcXExY8aMYfjw4QwePJhPPvnkhH137dpFamoqAMeOHWPSpEkMGDCAq6++ut7cU9OmTSM9PZ1Bgwbx8MMPA9YkiLm5uVxwwQVccMEFgDXFx6FDhwB49tlnSU1NJTU1leeee67ufAMGDOCuu+5i0KBBXHzxxY3OcfXpp58yatQohg0bxkUXXcT+/fsBKC4uZsqUKQwePJghQ4bUTSPy+eefM3z4cNLS0hgzZky976FWamoqu3btYteuXfTr149bbrmF1NRU9u7d2+jnA2vK9rPPPpu0tDQyMjIoKiri/PPPrzdw8dxzz2XNmjXN/hudCk8mjRwgxel9sr3MJcaYHPt5B7AIGObO4NQpcoTAkOth2n9g8hzrfhufPwh/HQQLn4SSw43vV3wATLVWTwWQiRMn1s37BNZMshMnTiQ8PJyPPvqIlStXsnDhQn7xi1/Q3MwUL774IpGRkWzatIlHH320bn4nsKY0z8zMZO3atXz77besXbuWBx54gMTERBYuXMjChQvrHWvFihXMnDmTpUuXsmTJEl5++eW6cRxZWVnce++9bNiwgfbt2zc6f9S5557LkiVLWLVqFZMmTeLPf/4zAI8//jixsbGsW7eOtWvXcuGFF3Lw4EHuuusuPvjgA9asWcOcOXNO+p1lZWVxzz33sGHDBrp3797o56uoqGDixIn87W9/Y82aNSxYsICIiAjuuOMO/vWvfwGwdetWysrKSEtLO+k5W8qTg/uWA31EpCdWspiEVWo4KRGJA0qNMeUikgCcA/zZY5GqlhOBvhdbjz1L4T/PwbdPwQ/Pw/Bb4Kx769/AqdDubqvVU75x6VNeP+WwYcM4cOAAubm5HDx4kLi4OFJSUqisrOR3v/sd3333HUFBQeTk5LB//366dOnS6HG+++47HnjgAQCGDBnCkCFD6tY1NqW58/qGFi9ezNVXX10339M111zD999/z/jx412agj07O5uJEyeSl5dHRUVF3TTvCxYsYPbs2XXbxcXF8emnn3L++efXbePKFOrdu3evNwdXS6ZsnzBhAo8//jhPP/00r732GrfddttJz3cqPJY0jDFVInIf8AXgAF4zxmwQkceATGPMXBEZCXwExAE/FZFHjTGDgAHASyJSg1UaesoYs9FTsapW6jYKur0DBzZbSWP5K7DsZRg8Ac6ZDp0H6hiNADVhwgTef/999u3bx8SJEwF4++23OXjwICtWrCAkJIQePXqc0lTk7prSvJYrU7Dff//9/PznP2f8+PF1d+VrKecp1KH+NOrOU6i39PNFRkYyduxYPvnkE9577716JTJ38mibhjFmnjGmrzGmtzHmCXvZQ8aYufbr5caYZGNMlDEm3k4YGGN+MMYMNsak2c+N325L+ZdO/eGqf8L0NTDqv2DTp1aD+ayJ1hxWoCWNADNx4kRmz57N+++/z4QJEwBravBOnToREhLCwoUL2b17d7PHOP/88+tmkl2/fj1r164Fmp7SHJqelv28887j448/prS0lJKSEj766CPOO+88lz9PQUEBSUlWf57XX3+9bvnYsWPrtd8cOXKEM888k++++46dO3cC9adQr71d68qVK+vWN9TSKdvBumHTAw88wMiRI5u84VRr+XNDuGqrYpNh3JPw3+th9O+s28aufAOCgiFKOywEkkGDBlFUVERSUhJdu1qlzBtvvJHMzEwGDx7MG2+8Qf/+/Zs9xrRp0yguLmbAgAE89NBDjBgxAmh6SnOAqVOnMm7cuLqG8FrDhw/ntttuIyMjg1GjRnHnnXcybJjrzaWPPPIIEyZMYMSIEfXuM/6HP/yBI0eOkJqaSlpaGgsXLqRjx47MmDGDa665hrS0tLqS1rXXXkt+fj6DBg3iH//4B3379m30XC2dsh2sarWYmBiP3ndDp0ZXnldRCqveAlMDZ97t62gChk6NHnhyc3MZPXo0mzdvJijoxDKBO6ZG15KG8rza7rqaMJTymDfeeINRo0bxxBNPNJow3EWnRldKqdPALbfcwi233OLx82hJQ6nT2OlS/axaz12/BU0aSp2mwsPDOXz4sCYOhTGGw4cPEx4e3upjafWUUqep5ORksrOz0XnZFFh/RCQnJ7f6OJo0lDpNhYSE1I1GVspdtHpKKaWUyzRpKKWUcpkmDaWUUi47bUaEi8hBoPlJbJqXABxyUzje0NbiBY3ZW9pazG0tXji9Yu5ujHF5fp/TJmm0lohktmQova+1tXhBY/aWthZzW4sXAjtmrZ5SSinlMk0aSimlXKZJ47gZvg6ghdpavKAxe0tbi7mtxQsBHLO2aSillHKZljSUUkq5TJOGUkoplwVU0hCRcSKyRUS2iciDjawPE5F37fVLRaSH96OsF0+KiCwUkY0iskFEpjeyzWgRKRCR1fbjIV/E2iCmXSKyzo7nhNspiuV5+3teKyLDfRGnUzz9nL6/1SJSKCI/a7CNz79nEXlNRA6IyHqnZR1E5CsRybKfG70xtIjcam+TJSK3+jDep0Vks/3v/pGItG9i32Z/Q16O+RERyXH6t7+siX2bvb54OeZ3neLdJSKrm9i35d+zMSYgHoAD2A70AkKBNcDABtvcA/yf/XoS8K6PY+4KDLdfRwNbG4l5NPBvX3+/DWLaBSQ0s/4yYD4gwJnAUl/H3OB3sg9rwJNffc/A+cBwYL3Tsj8DD9qvHwT+1Mh+HYAd9nOc/TrOR/FeDATbr//UWLyu/Ia8HPMjwC9d+N00e33xZswN1v8FeMhd33MglTQygG3GmB3GmApgNnBlg22uBF63X78PjBER8WKM9Rhj8owxK+3XRcAmIMlX8bjRlcAbxrIEaC8iXX0dlG0MsN0Y05rZBTzCGPMdkN9gsfNv9nXgqkZ2vQT4yhiTb4w5AnwFjPNYoLbG4jXGfGmMqbLfLgFaP1e3GzXxHbvCleuLRzQXs339uh54x13nC6SkkQTsdXqfzYkX4Lpt7B92ARDvlehOwq4qGwYsbWT1WSKyRkTmi8ggrwbWOAN8KSIrRGRqI+td+bfwlUk0/R/M375ngM7GmDz79T6gcyPb+Ov3fTtWibMxJ/sNedt9dpXaa01UAfrrd3wesN8Yk9XE+hZ/z4GUNNosEWkHfAD8zBhT2GD1SqyqlDTg78DH3o6vEecaY4YDlwL3isj5vg7IFSISCowH5jSy2h+/53qMVd/QJvrQi8jvgSrg7SY28aff0ItAb2AokIdV3dNW3EDzpYwWf8+BlDRygBSn98n2ska3EZFgIBY47JXomiAiIVgJ421jzIcN1xtjCo0xxfbreUCIiCR4OcyGMeXYz5rWF8kAAAP4SURBVAeAj7CK7s5c+bfwhUuBlcaY/Q1X+OP3bNtfW7VnPx9oZBu/+r5F5DbgCuBGO9GdwIXfkNcYY/YbY6qNMTXAy03E4lffMdRdw64B3m1qm1P5ngMpaSwH+ohIT/svyknA3AbbzAVqe5ZcB3zT1I/aG+z6yFeBTcaYZ5vYpkttu4uIZGD9m/os0YlIlIhE177Gavhc32CzucAtdi+qM4ECpyoWX2ryrzJ/+56dOP9mbwU+aWSbL4CLRSTOrlq52F7mdSIyDvg1MN4YU9rENq78hrymQXvb1U3E4sr1xdsuAjYbY7IbW3nK37M3Wvf95YHVa2crVi+H39vLHsP6AQOEY1VNbAOWAb18HO+5WNUNa4HV9uMy4G7gbnub+4ANWL01lgBn+zjmXnYsa+y4ar9n55gFeMH+d1gHpPvBbyMKKwnEOi3zq+8ZK6HlAZVYdeZ3YLW5fQ1kAQuADva26cArTvvebv+utwFTfBjvNqy6/9rfc21vxURgXnO/IR/G/Kb9O12LlQi6NozZfn/C9cVXMdvL/1X7+3XattXfs04jopRSymWBVD2llFKqlTRpKKWUcpkmDaWUUi7TpKGUUsplmjSUUkq5TJOGUj5kz577b1/HoZSrNGkopZRymSYNpVwgIjeJyDL7vgMviYhDRIpF5K9i3evkaxHpaG87VESWON0zIs5efoaILLAnPVwpIr3tw7cTkfft+0y87TTy/Cmx7qWyVkSe8dFHV6oeTRpKncT/t3f3rFFFURSG3yVCRCIJCDYW2okGNCBYGLXJHxCJCEqK1GnUxiaQIP4FQQuLiHaC2NlYDFglFlaWVqnSiKAQIcmy2EdjETPXIR8W64GB4cydc+8pZjZ3hrO2pLPALWDC9jiwAdyhdpF/sD0G9ID59pbnwAPb56mdxL/GXwKPXaGHl6ldvFDpxXeBc9Qu3QlJx6nIirE2z6O9XWVENykaEf1NAheB5dYBbZL6ct9kKwzuBXBF0ggwarvXxheBay3j56Tt1wC217yVvbRke8UViPcROE3F8q8BzyTdALbNaYrYbykaEf0JWLQ93h5nbC9sc9ygmTw//ni+QXW2W6cSR19RibBvB5w7YlelaET09w6YknQCfvflPkV9fqbaMbeB97a/Al8kXW3j00DP1XlxRdL1NseQpKN/O2HroTLiimG/B1zYi4VF/KvDB30BEf87258kzVEdzg5RaaKzwHfgUnttlfrfAyqi/EkrCp+BmTY+DTyV9LDNcXOH0x4D3kg6Qt3p3N/lZUUMJCm3EQOS9M328EFfR8R+ys9TERHRWe40IiKis9xpREREZykaERHRWYpGRER0lqIRERGdpWhERERnPwH9HUpnZhkwjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='validation accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(save_plot_name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
